{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8482394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>referee</th>\n",
       "      <th>winner</th>\n",
       "      <th>p1_height</th>\n",
       "      <th>p1_weight</th>\n",
       "      <th>p1_reach</th>\n",
       "      <th>p1_stance</th>\n",
       "      <th>p1_slpm</th>\n",
       "      <th>p1_str_acc</th>\n",
       "      <th>p1_sapm</th>\n",
       "      <th>p1_str_def</th>\n",
       "      <th>p1_td_avg</th>\n",
       "      <th>p1_td_acc</th>\n",
       "      <th>p1_td_def</th>\n",
       "      <th>p1_sub_avg</th>\n",
       "      <th>p2_height</th>\n",
       "      <th>p2_weight</th>\n",
       "      <th>p2_reach</th>\n",
       "      <th>p2_stance</th>\n",
       "      <th>p2_slpm</th>\n",
       "      <th>p2_str_acc</th>\n",
       "      <th>p2_sapm</th>\n",
       "      <th>p2_str_def</th>\n",
       "      <th>p2_td_avg</th>\n",
       "      <th>p2_td_acc</th>\n",
       "      <th>p2_td_def</th>\n",
       "      <th>p2_sub_avg</th>\n",
       "      <th>p1_age_at_event</th>\n",
       "      <th>p2_age_at_event</th>\n",
       "      <th>height_diff</th>\n",
       "      <th>reach_diff</th>\n",
       "      <th>weight_diff</th>\n",
       "      <th>age_diff</th>\n",
       "      <th>slpm_diff</th>\n",
       "      <th>stracc_diff</th>\n",
       "      <th>sapm_diff</th>\n",
       "      <th>strdef_diff</th>\n",
       "      <th>tdavg_diff</th>\n",
       "      <th>tdacc_diff</th>\n",
       "      <th>tddef_diff</th>\n",
       "      <th>subavg_diff</th>\n",
       "      <th>p1_days_since_last_fight</th>\n",
       "      <th>p2_days_since_last_fight</th>\n",
       "      <th>days_since_last_fight_diff</th>\n",
       "      <th>p1_wins</th>\n",
       "      <th>p1_losses</th>\n",
       "      <th>p1_total</th>\n",
       "      <th>p2_wins</th>\n",
       "      <th>p2_losses</th>\n",
       "      <th>p2_total</th>\n",
       "      <th>win_diff</th>\n",
       "      <th>loss_diff</th>\n",
       "      <th>total_diff</th>\n",
       "      <th>p1_win_streak</th>\n",
       "      <th>p2_win_streak</th>\n",
       "      <th>p1_age_adjusted_slpm</th>\n",
       "      <th>p2_age_adjusted_slpm</th>\n",
       "      <th>p1_age_adjusted_str_acc</th>\n",
       "      <th>p2_age_adjusted_str_acc</th>\n",
       "      <th>p1_age_adjusted_sapm</th>\n",
       "      <th>p2_age_adjusted_sapm</th>\n",
       "      <th>p1_age_adjusted_str_def</th>\n",
       "      <th>p2_age_adjusted_str_def</th>\n",
       "      <th>p1_age_adjusted_td_avg</th>\n",
       "      <th>p2_age_adjusted_td_avg</th>\n",
       "      <th>p1_age_adjusted_td_acc</th>\n",
       "      <th>p2_age_adjusted_td_acc</th>\n",
       "      <th>p1_age_adjusted_td_def</th>\n",
       "      <th>p2_age_adjusted_td_def</th>\n",
       "      <th>p1_age_adjusted_sub_avg</th>\n",
       "      <th>p2_age_adjusted_sub_avg</th>\n",
       "      <th>p1_kd_ema</th>\n",
       "      <th>p2_kd_ema</th>\n",
       "      <th>p1_sig_str_pct_ema</th>\n",
       "      <th>p2_sig_str_pct_ema</th>\n",
       "      <th>p1_td_pct_ema</th>\n",
       "      <th>p2_td_pct_ema</th>\n",
       "      <th>p1_sub_att_ema</th>\n",
       "      <th>p2_sub_att_ema</th>\n",
       "      <th>p1_rev_ema</th>\n",
       "      <th>p2_rev_ema</th>\n",
       "      <th>p1_ctrl_ema</th>\n",
       "      <th>p2_ctrl_ema</th>\n",
       "      <th>p1_r1_kd_ema</th>\n",
       "      <th>p2_r1_kd_ema</th>\n",
       "      <th>p1_r1_sig_str_pct_ema</th>\n",
       "      <th>p2_r1_sig_str_pct_ema</th>\n",
       "      <th>p1_r1_td_pct_ema</th>\n",
       "      <th>p2_r1_td_pct_ema</th>\n",
       "      <th>p1_r1_sub_att_ema</th>\n",
       "      <th>p2_r1_sub_att_ema</th>\n",
       "      <th>p1_r1_rev_ema</th>\n",
       "      <th>p2_r1_rev_ema</th>\n",
       "      <th>p1_r1_ctrl_ema</th>\n",
       "      <th>p2_r1_ctrl_ema</th>\n",
       "      <th>p1_sig_str_pct_detailed_ema</th>\n",
       "      <th>p2_sig_str_pct_detailed_ema</th>\n",
       "      <th>p1_r1_sig_str_pct_detailed_ema</th>\n",
       "      <th>p2_r1_sig_str_pct_detailed_ema</th>\n",
       "      <th>p1_sig_str_landed_ema</th>\n",
       "      <th>p2_sig_str_landed_ema</th>\n",
       "      <th>p1_sig_str_attempted_ema</th>\n",
       "      <th>p2_sig_str_attempted_ema</th>\n",
       "      <th>p1_total_str_landed_ema</th>\n",
       "      <th>p2_total_str_landed_ema</th>\n",
       "      <th>p1_total_str_attempted_ema</th>\n",
       "      <th>p2_total_str_attempted_ema</th>\n",
       "      <th>p1_td_landed_ema</th>\n",
       "      <th>p2_td_landed_ema</th>\n",
       "      <th>p1_td_attempted_ema</th>\n",
       "      <th>p2_td_attempted_ema</th>\n",
       "      <th>p1_r1_sig_str_landed_ema</th>\n",
       "      <th>p2_r1_sig_str_landed_ema</th>\n",
       "      <th>p1_r1_sig_str_attempted_ema</th>\n",
       "      <th>p2_r1_sig_str_attempted_ema</th>\n",
       "      <th>p1_r1_total_str_landed_ema</th>\n",
       "      <th>p2_r1_total_str_landed_ema</th>\n",
       "      <th>p1_r1_total_str_attempted_ema</th>\n",
       "      <th>p2_r1_total_str_attempted_ema</th>\n",
       "      <th>p1_r1_td_landed_ema</th>\n",
       "      <th>p2_r1_td_landed_ema</th>\n",
       "      <th>p1_r1_td_attempted_ema</th>\n",
       "      <th>p2_r1_td_attempted_ema</th>\n",
       "      <th>p1_head_landed_ema</th>\n",
       "      <th>p2_head_landed_ema</th>\n",
       "      <th>p1_head_attempted_ema</th>\n",
       "      <th>p2_head_attempted_ema</th>\n",
       "      <th>p1_body_landed_ema</th>\n",
       "      <th>p2_body_landed_ema</th>\n",
       "      <th>p1_body_attempted_ema</th>\n",
       "      <th>p2_body_attempted_ema</th>\n",
       "      <th>p1_leg_landed_ema</th>\n",
       "      <th>p2_leg_landed_ema</th>\n",
       "      <th>p1_leg_attempted_ema</th>\n",
       "      <th>p2_leg_attempted_ema</th>\n",
       "      <th>p1_distance_landed_ema</th>\n",
       "      <th>p2_distance_landed_ema</th>\n",
       "      <th>p1_distance_attempted_ema</th>\n",
       "      <th>p2_distance_attempted_ema</th>\n",
       "      <th>p1_clinch_landed_ema</th>\n",
       "      <th>p2_clinch_landed_ema</th>\n",
       "      <th>p1_clinch_attempted_ema</th>\n",
       "      <th>p2_clinch_attempted_ema</th>\n",
       "      <th>p1_ground_landed_ema</th>\n",
       "      <th>p2_ground_landed_ema</th>\n",
       "      <th>p1_ground_attempted_ema</th>\n",
       "      <th>p2_ground_attempted_ema</th>\n",
       "      <th>p1_r1_head_landed_ema</th>\n",
       "      <th>p2_r1_head_landed_ema</th>\n",
       "      <th>p1_r1_head_attempted_ema</th>\n",
       "      <th>p2_r1_head_attempted_ema</th>\n",
       "      <th>p1_r1_body_landed_ema</th>\n",
       "      <th>p2_r1_body_landed_ema</th>\n",
       "      <th>p1_r1_body_attempted_ema</th>\n",
       "      <th>p2_r1_body_attempted_ema</th>\n",
       "      <th>p1_r1_leg_landed_ema</th>\n",
       "      <th>p2_r1_leg_landed_ema</th>\n",
       "      <th>p1_r1_leg_attempted_ema</th>\n",
       "      <th>p2_r1_leg_attempted_ema</th>\n",
       "      <th>p1_r1_distance_landed_ema</th>\n",
       "      <th>p2_r1_distance_landed_ema</th>\n",
       "      <th>p1_r1_distance_attempted_ema</th>\n",
       "      <th>p2_r1_distance_attempted_ema</th>\n",
       "      <th>p1_r1_clinch_landed_ema</th>\n",
       "      <th>p2_r1_clinch_landed_ema</th>\n",
       "      <th>p1_r1_clinch_attempted_ema</th>\n",
       "      <th>p2_r1_clinch_attempted_ema</th>\n",
       "      <th>p1_r1_ground_landed_ema</th>\n",
       "      <th>p2_r1_ground_landed_ema</th>\n",
       "      <th>p1_r1_ground_attempted_ema</th>\n",
       "      <th>p2_r1_ground_attempted_ema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan Miragliotta</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Switch</td>\n",
       "      <td>5.02</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.4</td>\n",
       "      <td>33.034908</td>\n",
       "      <td>37.374401</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.339493</td>\n",
       "      <td>2.11</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.151960</td>\n",
       "      <td>0.077861</td>\n",
       "      <td>0.013319</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.104738</td>\n",
       "      <td>0.094985</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>0.013111</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>0.043345</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.009097</td>\n",
       "      <td>0.019071</td>\n",
       "      <td>0.016054</td>\n",
       "      <td>0.009081</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.299520</td>\n",
       "      <td>0.427808</td>\n",
       "      <td>0.499030</td>\n",
       "      <td>0.295141</td>\n",
       "      <td>0.250166</td>\n",
       "      <td>0.266130</td>\n",
       "      <td>0.319192</td>\n",
       "      <td>0.032290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>369.136117</td>\n",
       "      <td>174.851985</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.434544</td>\n",
       "      <td>0.846666</td>\n",
       "      <td>0.664548</td>\n",
       "      <td>0.467068</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>0.037895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.763841</td>\n",
       "      <td>98.073334</td>\n",
       "      <td>0.427808</td>\n",
       "      <td>0.499030</td>\n",
       "      <td>0.434544</td>\n",
       "      <td>0.846666</td>\n",
       "      <td>73.462980</td>\n",
       "      <td>44.916534</td>\n",
       "      <td>168.352377</td>\n",
       "      <td>94.296907</td>\n",
       "      <td>112.881890</td>\n",
       "      <td>50.330579</td>\n",
       "      <td>222.104682</td>\n",
       "      <td>99.836223</td>\n",
       "      <td>2.220167</td>\n",
       "      <td>1.953972</td>\n",
       "      <td>5.331929</td>\n",
       "      <td>8.821761</td>\n",
       "      <td>17.268388</td>\n",
       "      <td>5.361112</td>\n",
       "      <td>38.845877</td>\n",
       "      <td>7.721747</td>\n",
       "      <td>24.855216</td>\n",
       "      <td>8.417673</td>\n",
       "      <td>50.872063</td>\n",
       "      <td>10.778392</td>\n",
       "      <td>0.625343</td>\n",
       "      <td>1.141289</td>\n",
       "      <td>1.002075</td>\n",
       "      <td>2.395547</td>\n",
       "      <td>40.424648</td>\n",
       "      <td>20.674029</td>\n",
       "      <td>123.293902</td>\n",
       "      <td>61.038605</td>\n",
       "      <td>13.657023</td>\n",
       "      <td>17.218732</td>\n",
       "      <td>22.233046</td>\n",
       "      <td>24.789088</td>\n",
       "      <td>19.381310</td>\n",
       "      <td>7.023773</td>\n",
       "      <td>22.825429</td>\n",
       "      <td>8.469213</td>\n",
       "      <td>64.249344</td>\n",
       "      <td>40.422319</td>\n",
       "      <td>153.012147</td>\n",
       "      <td>87.092312</td>\n",
       "      <td>0.629677</td>\n",
       "      <td>2.975746</td>\n",
       "      <td>1.600867</td>\n",
       "      <td>4.961387</td>\n",
       "      <td>8.583959</td>\n",
       "      <td>1.518469</td>\n",
       "      <td>13.739364</td>\n",
       "      <td>2.243207</td>\n",
       "      <td>7.499725</td>\n",
       "      <td>1.992489</td>\n",
       "      <td>25.974974</td>\n",
       "      <td>4.131527</td>\n",
       "      <td>3.184765</td>\n",
       "      <td>1.563864</td>\n",
       "      <td>5.100348</td>\n",
       "      <td>1.722838</td>\n",
       "      <td>6.583898</td>\n",
       "      <td>1.804759</td>\n",
       "      <td>7.770555</td>\n",
       "      <td>1.867382</td>\n",
       "      <td>14.666789</td>\n",
       "      <td>4.508493</td>\n",
       "      <td>33.379235</td>\n",
       "      <td>6.492636</td>\n",
       "      <td>0.094732</td>\n",
       "      <td>0.313642</td>\n",
       "      <td>0.438809</td>\n",
       "      <td>0.438894</td>\n",
       "      <td>2.506867</td>\n",
       "      <td>0.538977</td>\n",
       "      <td>5.027834</td>\n",
       "      <td>0.790218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tyrone Roberts</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.35</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.632444</td>\n",
       "      <td>33.541410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.908966</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-2.95</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114610</td>\n",
       "      <td>0.090038</td>\n",
       "      <td>0.015322</td>\n",
       "      <td>0.010435</td>\n",
       "      <td>0.078756</td>\n",
       "      <td>0.164573</td>\n",
       "      <td>0.015935</td>\n",
       "      <td>0.013416</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>0.050684</td>\n",
       "      <td>0.030644</td>\n",
       "      <td>0.006857</td>\n",
       "      <td>0.012871</td>\n",
       "      <td>0.029814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567143</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.393333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>168.571429</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.571429</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>0.567143</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.545714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>47.285714</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>84.142857</td>\n",
       "      <td>126.333333</td>\n",
       "      <td>63.571429</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>102.142857</td>\n",
       "      <td>135.666667</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>41.142857</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>23.714286</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>43.142857</td>\n",
       "      <td>57.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.142857</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>102.333333</td>\n",
       "      <td>13.857143</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>12.285714</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.142857</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>30.714286</td>\n",
       "      <td>44.333333</td>\n",
       "      <td>61.571429</td>\n",
       "      <td>119.666667</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>16.857143</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>20.571429</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>10.285714</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.857143</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>38.857143</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kevin MacDonald</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>4.42</td>\n",
       "      <td>0.58</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.3</td>\n",
       "      <td>35.474333</td>\n",
       "      <td>38.707734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.233402</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>266.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>-252.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124597</td>\n",
       "      <td>0.067687</td>\n",
       "      <td>0.016350</td>\n",
       "      <td>0.011626</td>\n",
       "      <td>0.087951</td>\n",
       "      <td>0.076987</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.013176</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.052186</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>0.008009</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.033585</td>\n",
       "      <td>0.500489</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.625855</td>\n",
       "      <td>0.665875</td>\n",
       "      <td>0.586522</td>\n",
       "      <td>0.461598</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.528751</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>124.804497</td>\n",
       "      <td>415.556831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.668456</td>\n",
       "      <td>0.667600</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.621714</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>53.725318</td>\n",
       "      <td>180.858625</td>\n",
       "      <td>0.625855</td>\n",
       "      <td>0.665875</td>\n",
       "      <td>0.668456</td>\n",
       "      <td>0.667600</td>\n",
       "      <td>77.987292</td>\n",
       "      <td>57.932243</td>\n",
       "      <td>119.926686</td>\n",
       "      <td>105.343182</td>\n",
       "      <td>133.727273</td>\n",
       "      <td>121.433525</td>\n",
       "      <td>187.241447</td>\n",
       "      <td>180.664144</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>2.365645</td>\n",
       "      <td>0.054741</td>\n",
       "      <td>5.704920</td>\n",
       "      <td>28.726295</td>\n",
       "      <td>17.898547</td>\n",
       "      <td>42.915934</td>\n",
       "      <td>29.821267</td>\n",
       "      <td>48.221896</td>\n",
       "      <td>39.323282</td>\n",
       "      <td>65.002933</td>\n",
       "      <td>55.751557</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.595288</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>1.565743</td>\n",
       "      <td>21.695015</td>\n",
       "      <td>40.738005</td>\n",
       "      <td>52.746823</td>\n",
       "      <td>78.202661</td>\n",
       "      <td>32.728250</td>\n",
       "      <td>14.005860</td>\n",
       "      <td>40.544477</td>\n",
       "      <td>22.364058</td>\n",
       "      <td>23.564027</td>\n",
       "      <td>3.188377</td>\n",
       "      <td>26.635386</td>\n",
       "      <td>4.776462</td>\n",
       "      <td>48.708700</td>\n",
       "      <td>35.804908</td>\n",
       "      <td>84.446725</td>\n",
       "      <td>78.584300</td>\n",
       "      <td>28.599218</td>\n",
       "      <td>6.882920</td>\n",
       "      <td>34.564027</td>\n",
       "      <td>9.668172</td>\n",
       "      <td>0.679374</td>\n",
       "      <td>15.244415</td>\n",
       "      <td>0.915934</td>\n",
       "      <td>17.090709</td>\n",
       "      <td>8.709677</td>\n",
       "      <td>13.189843</td>\n",
       "      <td>21.014663</td>\n",
       "      <td>21.444879</td>\n",
       "      <td>11.351906</td>\n",
       "      <td>3.692956</td>\n",
       "      <td>12.464321</td>\n",
       "      <td>6.984129</td>\n",
       "      <td>8.664712</td>\n",
       "      <td>1.015749</td>\n",
       "      <td>9.436950</td>\n",
       "      <td>1.392260</td>\n",
       "      <td>17.914956</td>\n",
       "      <td>8.209010</td>\n",
       "      <td>29.654936</td>\n",
       "      <td>18.979856</td>\n",
       "      <td>10.704790</td>\n",
       "      <td>2.588939</td>\n",
       "      <td>13.144673</td>\n",
       "      <td>3.738738</td>\n",
       "      <td>0.106549</td>\n",
       "      <td>7.100598</td>\n",
       "      <td>0.116325</td>\n",
       "      <td>7.102674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mike Beltran</td>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.38</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.6</td>\n",
       "      <td>34.652977</td>\n",
       "      <td>29.300479</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.352498</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>3.28</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>105.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.094653</td>\n",
       "      <td>0.090442</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>0.021501</td>\n",
       "      <td>0.077627</td>\n",
       "      <td>0.063480</td>\n",
       "      <td>0.010966</td>\n",
       "      <td>0.021843</td>\n",
       "      <td>0.198829</td>\n",
       "      <td>0.123206</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.028858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057715</td>\n",
       "      <td>0.122865</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.608667</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>206.333333</td>\n",
       "      <td>128.933333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.571333</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>151.333333</td>\n",
       "      <td>80.933333</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.608667</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.571333</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>31.933333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>50.400000</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>41.933333</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>62.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>10.866667</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>16.066667</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>25.733333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>31.066667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.533333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.066667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>10.133333</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>47.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.266667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kevin MacDonald</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.1</td>\n",
       "      <td>38.600958</td>\n",
       "      <td>38.338125</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262834</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>-91.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124349</td>\n",
       "      <td>0.195628</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.012781</td>\n",
       "      <td>0.119427</td>\n",
       "      <td>0.142678</td>\n",
       "      <td>0.015803</td>\n",
       "      <td>0.015129</td>\n",
       "      <td>0.014507</td>\n",
       "      <td>0.015389</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.014868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.568214</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.409565</td>\n",
       "      <td>0.457250</td>\n",
       "      <td>0.306089</td>\n",
       "      <td>0.879828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>58.837074</td>\n",
       "      <td>33.627839</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.405490</td>\n",
       "      <td>0.444244</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.003412</td>\n",
       "      <td>1.010745</td>\n",
       "      <td>0.409565</td>\n",
       "      <td>0.457250</td>\n",
       "      <td>0.405490</td>\n",
       "      <td>0.444244</td>\n",
       "      <td>63.825189</td>\n",
       "      <td>104.030037</td>\n",
       "      <td>152.684444</td>\n",
       "      <td>215.924054</td>\n",
       "      <td>64.124443</td>\n",
       "      <td>107.503541</td>\n",
       "      <td>152.983705</td>\n",
       "      <td>220.185348</td>\n",
       "      <td>0.549813</td>\n",
       "      <td>0.500611</td>\n",
       "      <td>1.518626</td>\n",
       "      <td>0.570940</td>\n",
       "      <td>18.632159</td>\n",
       "      <td>27.584860</td>\n",
       "      <td>44.955530</td>\n",
       "      <td>59.124786</td>\n",
       "      <td>18.632432</td>\n",
       "      <td>27.745055</td>\n",
       "      <td>44.955805</td>\n",
       "      <td>59.538950</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.062515</td>\n",
       "      <td>44.064673</td>\n",
       "      <td>48.864225</td>\n",
       "      <td>125.755292</td>\n",
       "      <td>145.810745</td>\n",
       "      <td>8.460826</td>\n",
       "      <td>38.950672</td>\n",
       "      <td>13.522847</td>\n",
       "      <td>52.964347</td>\n",
       "      <td>11.299691</td>\n",
       "      <td>16.215140</td>\n",
       "      <td>13.406304</td>\n",
       "      <td>17.148962</td>\n",
       "      <td>61.410415</td>\n",
       "      <td>100.666911</td>\n",
       "      <td>146.797878</td>\n",
       "      <td>212.363614</td>\n",
       "      <td>0.302455</td>\n",
       "      <td>3.201954</td>\n",
       "      <td>0.677917</td>\n",
       "      <td>3.210745</td>\n",
       "      <td>2.112320</td>\n",
       "      <td>0.161172</td>\n",
       "      <td>5.208649</td>\n",
       "      <td>0.349695</td>\n",
       "      <td>10.050556</td>\n",
       "      <td>11.164835</td>\n",
       "      <td>34.478522</td>\n",
       "      <td>38.309402</td>\n",
       "      <td>4.698507</td>\n",
       "      <td>10.136752</td>\n",
       "      <td>6.146630</td>\n",
       "      <td>14.217582</td>\n",
       "      <td>3.883096</td>\n",
       "      <td>6.283272</td>\n",
       "      <td>4.330378</td>\n",
       "      <td>6.597802</td>\n",
       "      <td>18.613174</td>\n",
       "      <td>27.526252</td>\n",
       "      <td>44.685991</td>\n",
       "      <td>59.010256</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>0.267689</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.050794</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.098657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           referee  winner  p1_height  p1_weight  p1_reach p1_stance  p1_slpm  \\\n",
       "0  Dan Miragliotta       1       71.0      135.0      70.0    Switch     5.02   \n",
       "1   Tyrone Roberts       0       67.0      135.0      69.0  Orthodox     3.74   \n",
       "2  Kevin MacDonald       1       66.0      135.0      68.0  Orthodox     4.42   \n",
       "3     Mike Beltran       1       76.0      185.0      78.0  Southpaw     3.28   \n",
       "4  Kevin MacDonald       0       72.0      170.0      73.0  Orthodox     4.80   \n",
       "\n",
       "   p1_str_acc  p1_sapm  p1_str_def  p1_td_avg  p1_td_acc  p1_td_def  \\\n",
       "0        0.44     3.46        0.56       1.19       0.32       0.63   \n",
       "1        0.50     2.57        0.52       0.78       1.00       0.42   \n",
       "2        0.58     3.12        0.50       0.97       0.53       0.42   \n",
       "3        0.57     2.69        0.38       6.89       0.46       1.00   \n",
       "4        0.41     4.61        0.61       0.56       0.32       0.71   \n",
       "\n",
       "   p1_sub_avg  p2_height  p2_weight  p2_reach p2_stance  p2_slpm  p2_str_acc  \\\n",
       "0         0.3       65.0      135.0      68.0  Orthodox     2.91        0.54   \n",
       "1         0.0       66.0      135.0      70.0  Orthodox     3.02        0.35   \n",
       "2         0.1       66.0      135.0      65.0  Orthodox     2.62        0.45   \n",
       "3         2.0       73.0      185.0      76.0  Southpaw     2.65        0.63   \n",
       "4         0.0       73.0      170.0      74.0  Southpaw     7.50        0.49   \n",
       "\n",
       "   p2_sapm  p2_str_def  p2_td_avg  p2_td_acc  p2_td_def  p2_sub_avg  \\\n",
       "0     3.55        0.49       1.62       0.34       0.60         1.4   \n",
       "1     5.52        0.45       1.70       0.23       1.00         0.0   \n",
       "2     2.98        0.51       2.02       0.31       0.55         1.3   \n",
       "3     1.86        0.64       3.61       0.50       0.00         3.6   \n",
       "4     5.47        0.58       0.59       0.54       0.57         0.1   \n",
       "\n",
       "   p1_age_at_event  p2_age_at_event  height_diff  reach_diff  weight_diff  \\\n",
       "0        33.034908        37.374401          6.0         2.0          0.0   \n",
       "1        32.632444        33.541410          1.0        -1.0          0.0   \n",
       "2        35.474333        38.707734          0.0         3.0          0.0   \n",
       "3        34.652977        29.300479          3.0         2.0          0.0   \n",
       "4        38.600958        38.338125         -1.0        -1.0          0.0   \n",
       "\n",
       "   age_diff  slpm_diff  stracc_diff  sapm_diff  strdef_diff  tdavg_diff  \\\n",
       "0 -4.339493       2.11        -0.10      -0.09         0.07       -0.43   \n",
       "1 -0.908966       0.72         0.15      -2.95         0.07       -0.92   \n",
       "2 -3.233402       1.80         0.13       0.14        -0.01       -1.05   \n",
       "3  5.352498       0.63        -0.06       0.83        -0.26        3.28   \n",
       "4  0.262834      -2.70        -0.08      -0.86         0.03       -0.03   \n",
       "\n",
       "   tdacc_diff  tddef_diff  subavg_diff  p1_days_since_last_fight  \\\n",
       "0       -0.02        0.03         -1.1                     273.0   \n",
       "1        0.77       -0.58          0.0                     175.0   \n",
       "2        0.22       -0.13         -1.2                     266.0   \n",
       "3       -0.04        1.00         -1.6                     105.0   \n",
       "4       -0.22        0.14         -0.1                     112.0   \n",
       "\n",
       "   p2_days_since_last_fight  days_since_last_fight_diff  p1_wins  p1_losses  \\\n",
       "0                     161.0                       112.0       10          4   \n",
       "1                     161.0                        14.0        2          1   \n",
       "2                     518.0                      -252.0        5          5   \n",
       "3                     168.0                       -63.0        2          0   \n",
       "4                     203.0                       -91.0       12          7   \n",
       "\n",
       "   p1_total  p2_wins  p2_losses  p2_total  win_diff  loss_diff  total_diff  \\\n",
       "0        14       13          5        18        -3         -1          -4   \n",
       "1         3        0          2         2         2         -1           1   \n",
       "2        10        7          6        13        -2         -1          -3   \n",
       "3         2        4          0         4        -2          0          -2   \n",
       "4        19        8          4        12         4          3           7   \n",
       "\n",
       "   p1_win_streak  p2_win_streak  p1_age_adjusted_slpm  p2_age_adjusted_slpm  \\\n",
       "0              0              0              0.151960              0.077861   \n",
       "1              1              0              0.114610              0.090038   \n",
       "2              1              1              0.124597              0.067687   \n",
       "3              2              4              0.094653              0.090442   \n",
       "4              1              1              0.124349              0.195628   \n",
       "\n",
       "   p1_age_adjusted_str_acc  p2_age_adjusted_str_acc  p1_age_adjusted_sapm  \\\n",
       "0                 0.013319                 0.014448              0.104738   \n",
       "1                 0.015322                 0.010435              0.078756   \n",
       "2                 0.016350                 0.011626              0.087951   \n",
       "3                 0.016449                 0.021501              0.077627   \n",
       "4                 0.010621                 0.012781              0.119427   \n",
       "\n",
       "   p2_age_adjusted_sapm  p1_age_adjusted_str_def  p2_age_adjusted_str_def  \\\n",
       "0              0.094985                 0.016952                 0.013111   \n",
       "1              0.164573                 0.015935                 0.013416   \n",
       "2              0.076987                 0.014095                 0.013176   \n",
       "3              0.063480                 0.010966                 0.021843   \n",
       "4              0.142678                 0.015803                 0.015129   \n",
       "\n",
       "   p1_age_adjusted_td_avg  p2_age_adjusted_td_avg  p1_age_adjusted_td_acc  \\\n",
       "0                0.036023                0.043345                0.009687   \n",
       "1                0.023903                0.050684                0.030644   \n",
       "2                0.027344                0.052186                0.014940   \n",
       "3                0.198829                0.123206                0.013274   \n",
       "4                0.014507                0.015389                0.008290   \n",
       "\n",
       "   p2_age_adjusted_td_acc  p1_age_adjusted_td_def  p2_age_adjusted_td_def  \\\n",
       "0                0.009097                0.019071                0.016054   \n",
       "1                0.006857                0.012871                0.029814   \n",
       "2                0.008009                0.011840                0.014209   \n",
       "3                0.017065                0.028858                0.000000   \n",
       "4                0.014085                0.018393                0.014868   \n",
       "\n",
       "   p1_age_adjusted_sub_avg  p2_age_adjusted_sub_avg  p1_kd_ema  p2_kd_ema  \\\n",
       "0                 0.009081                 0.037459   0.012025   0.299520   \n",
       "1                 0.000000                 0.000000   0.000000   0.000000   \n",
       "2                 0.002819                 0.033585   0.500489   0.003907   \n",
       "3                 0.057715                 0.122865   0.333333   0.133333   \n",
       "4                 0.000000                 0.002608   0.568214   0.003175   \n",
       "\n",
       "   p1_sig_str_pct_ema  p2_sig_str_pct_ema  p1_td_pct_ema  p2_td_pct_ema  \\\n",
       "0            0.427808            0.499030       0.295141       0.250166   \n",
       "1            0.567143            0.350000       1.000000       0.393333   \n",
       "2            0.625855            0.665875       0.586522       0.461598   \n",
       "3            0.570000            0.608667       0.793333       0.321429   \n",
       "4            0.409565            0.457250       0.306089       0.879828   \n",
       "\n",
       "   p1_sub_att_ema  p2_sub_att_ema  p1_rev_ema  p2_rev_ema  p1_ctrl_ema  \\\n",
       "0        0.266130        0.319192    0.032290    0.000000   369.136117   \n",
       "1        0.000000        0.000000    0.714286    0.000000   168.571429   \n",
       "2        0.001955        0.528751    0.007820    0.002198   124.804497   \n",
       "3        1.000000        0.666667    0.000000    0.000000   206.333333   \n",
       "4        0.000000        0.000244    0.000000    0.015629    58.837074   \n",
       "\n",
       "   p2_ctrl_ema  p1_r1_kd_ema  p2_r1_kd_ema  p1_r1_sig_str_pct_ema  \\\n",
       "0   174.851985      0.008057      0.001953               0.434544   \n",
       "1    86.333333      0.000000      0.000000               0.545714   \n",
       "2   415.556831      0.000000      0.003907               0.668456   \n",
       "3   128.933333      0.333333      0.133333               0.553333   \n",
       "4    33.627839      0.000584      0.003175               0.405490   \n",
       "\n",
       "   p2_r1_sig_str_pct_ema  p1_r1_td_pct_ema  p2_r1_td_pct_ema  \\\n",
       "0               0.846666          0.664548          0.467068   \n",
       "1               0.333333               NaN          0.660000   \n",
       "2               0.667600          0.750000          0.621714   \n",
       "3               0.571333          0.776667          0.321429   \n",
       "4               0.444244          0.333333          0.000000   \n",
       "\n",
       "   p1_r1_sub_att_ema  p2_r1_sub_att_ema  p1_r1_rev_ema  p2_r1_rev_ema  \\\n",
       "0           0.016114           0.037895       0.000000       0.000000   \n",
       "1           0.000000           0.000000       0.571429       0.000000   \n",
       "2           0.001955           0.000000       0.007820       0.000244   \n",
       "3           0.666667           0.133333       0.000000       0.000000   \n",
       "4           0.000000           0.000000       0.000000       0.000000   \n",
       "\n",
       "   p1_r1_ctrl_ema  p2_r1_ctrl_ema  p1_sig_str_pct_detailed_ema  \\\n",
       "0       62.763841       98.073334                     0.427808   \n",
       "1       52.571429       14.666667                     0.567143   \n",
       "2       53.725318      180.858625                     0.625855   \n",
       "3      151.333333       80.933333                     0.570000   \n",
       "4        2.003412        1.010745                     0.409565   \n",
       "\n",
       "   p2_sig_str_pct_detailed_ema  p1_r1_sig_str_pct_detailed_ema  \\\n",
       "0                     0.499030                        0.434544   \n",
       "1                     0.350000                        0.545714   \n",
       "2                     0.665875                        0.668456   \n",
       "3                     0.608667                        0.553333   \n",
       "4                     0.457250                        0.405490   \n",
       "\n",
       "   p2_r1_sig_str_pct_detailed_ema  p1_sig_str_landed_ema  \\\n",
       "0                        0.846666              73.462980   \n",
       "1                        0.333333              47.285714   \n",
       "2                        0.667600              77.987292   \n",
       "3                        0.571333              20.666667   \n",
       "4                        0.444244              63.825189   \n",
       "\n",
       "   p2_sig_str_landed_ema  p1_sig_str_attempted_ema  p2_sig_str_attempted_ema  \\\n",
       "0              44.916534                168.352377                 94.296907   \n",
       "1              48.000000                 84.142857                126.333333   \n",
       "2              57.932243                119.926686                105.343182   \n",
       "3              31.933333                 36.000000                 50.400000   \n",
       "4             104.030037                152.684444                215.924054   \n",
       "\n",
       "   p1_total_str_landed_ema  p2_total_str_landed_ema  \\\n",
       "0               112.881890                50.330579   \n",
       "1                63.571429                56.000000   \n",
       "2               133.727273               121.433525   \n",
       "3                44.666667                41.933333   \n",
       "4                64.124443               107.503541   \n",
       "\n",
       "   p1_total_str_attempted_ema  p2_total_str_attempted_ema  p1_td_landed_ema  \\\n",
       "0                  222.104682                   99.836223          2.220167   \n",
       "1                  102.142857                  135.666667          1.142857   \n",
       "2                  187.241447                  180.664144          0.030303   \n",
       "3                   61.333333                   62.800000          3.000000   \n",
       "4                  152.983705                  220.185348          0.549813   \n",
       "\n",
       "   p2_td_landed_ema  p1_td_attempted_ema  p2_td_attempted_ema  \\\n",
       "0          1.953972             5.331929             8.821761   \n",
       "1          1.333333             1.142857             5.000000   \n",
       "2          2.365645             0.054741             5.704920   \n",
       "3          0.866667             5.666667             2.000000   \n",
       "4          0.500611             1.518626             0.570940   \n",
       "\n",
       "   p1_r1_sig_str_landed_ema  p2_r1_sig_str_landed_ema  \\\n",
       "0                 17.268388                  5.361112   \n",
       "1                 22.571429                 21.000000   \n",
       "2                 28.726295                 17.898547   \n",
       "3                 17.333333                 10.866667   \n",
       "4                 18.632159                 27.584860   \n",
       "\n",
       "   p1_r1_sig_str_attempted_ema  p2_r1_sig_str_attempted_ema  \\\n",
       "0                    38.845877                     7.721747   \n",
       "1                    41.142857                    55.333333   \n",
       "2                    42.915934                    29.821267   \n",
       "3                    31.666667                    20.000000   \n",
       "4                    44.955530                    59.124786   \n",
       "\n",
       "   p1_r1_total_str_landed_ema  p2_r1_total_str_landed_ema  \\\n",
       "0                   24.855216                    8.417673   \n",
       "1                   23.714286                   22.333333   \n",
       "2                   48.221896                   39.323282   \n",
       "3                   28.333333                   16.066667   \n",
       "4                   18.632432                   27.745055   \n",
       "\n",
       "   p1_r1_total_str_attempted_ema  p2_r1_total_str_attempted_ema  \\\n",
       "0                      50.872063                      10.778392   \n",
       "1                      43.142857                      57.333333   \n",
       "2                      65.002933                      55.751557   \n",
       "3                      43.000000                      25.733333   \n",
       "4                      44.955805                      59.538950   \n",
       "\n",
       "   p1_r1_td_landed_ema  p2_r1_td_landed_ema  p1_r1_td_attempted_ema  \\\n",
       "0             0.625343             1.141289                1.002075   \n",
       "1             0.000000             0.666667                0.000000   \n",
       "2             0.008798             0.595288                0.015640   \n",
       "3             2.000000             0.600000                3.333333   \n",
       "4             0.000008             0.000000                0.000053   \n",
       "\n",
       "   p2_r1_td_attempted_ema  p1_head_landed_ema  p2_head_landed_ema  \\\n",
       "0                2.395547           40.424648           20.674029   \n",
       "1                1.000000           21.142857           28.000000   \n",
       "2                1.565743           21.695015           40.738005   \n",
       "3                1.466667           13.666667           15.333333   \n",
       "4                0.062515           44.064673           48.864225   \n",
       "\n",
       "   p1_head_attempted_ema  p2_head_attempted_ema  p1_body_landed_ema  \\\n",
       "0             123.293902              61.038605           13.657023   \n",
       "1              52.000000             102.333333           13.857143   \n",
       "2              52.746823              78.202661           32.728250   \n",
       "3              27.333333              31.066667            4.000000   \n",
       "4             125.755292             145.810745            8.460826   \n",
       "\n",
       "   p2_body_landed_ema  p1_body_attempted_ema  p2_body_attempted_ema  \\\n",
       "0           17.218732              22.233046              24.789088   \n",
       "1           17.000000              18.000000              20.666667   \n",
       "2           14.005860              40.544477              22.364058   \n",
       "3            7.533333               5.000000               9.200000   \n",
       "4           38.950672              13.522847              52.964347   \n",
       "\n",
       "   p1_leg_landed_ema  p2_leg_landed_ema  p1_leg_attempted_ema  \\\n",
       "0          19.381310           7.023773             22.825429   \n",
       "1          12.285714           3.000000             14.142857   \n",
       "2          23.564027           3.188377             26.635386   \n",
       "3           3.000000           9.066667              3.666667   \n",
       "4          11.299691          16.215140             13.406304   \n",
       "\n",
       "   p2_leg_attempted_ema  p1_distance_landed_ema  p2_distance_landed_ema  \\\n",
       "0              8.469213               64.249344               40.422319   \n",
       "1              3.333333               30.714286               44.333333   \n",
       "2              4.776462               48.708700               35.804908   \n",
       "3             10.133333               11.333333               30.400000   \n",
       "4             17.148962               61.410415              100.666911   \n",
       "\n",
       "   p1_distance_attempted_ema  p2_distance_attempted_ema  p1_clinch_landed_ema  \\\n",
       "0                 153.012147                  87.092312              0.629677   \n",
       "1                  61.571429                 119.666667              5.142857   \n",
       "2                  84.446725                  78.584300             28.599218   \n",
       "3                  20.333333                  47.933333              1.000000   \n",
       "4                 146.797878                 212.363614              0.302455   \n",
       "\n",
       "   p2_clinch_landed_ema  p1_clinch_attempted_ema  p2_clinch_attempted_ema  \\\n",
       "0              2.975746                 1.600867                 4.961387   \n",
       "1              3.333333                 5.714286                 4.666667   \n",
       "2              6.882920                34.564027                 9.668172   \n",
       "3              0.066667                 1.333333                 0.200000   \n",
       "4              3.201954                 0.677917                 3.210745   \n",
       "\n",
       "   p1_ground_landed_ema  p2_ground_landed_ema  p1_ground_attempted_ema  \\\n",
       "0              8.583959              1.518469                13.739364   \n",
       "1             11.428571              0.333333                16.857143   \n",
       "2              0.679374             15.244415                 0.915934   \n",
       "3              8.333333              1.466667                14.333333   \n",
       "4              2.112320              0.161172                 5.208649   \n",
       "\n",
       "   p2_ground_attempted_ema  p1_r1_head_landed_ema  p2_r1_head_landed_ema  \\\n",
       "0                 2.243207               7.499725               1.992489   \n",
       "1                 2.000000               5.285714              12.666667   \n",
       "2                17.090709               8.709677              13.189843   \n",
       "3                 2.266667              12.000000               4.933333   \n",
       "4                 0.349695              10.050556              11.164835   \n",
       "\n",
       "   p1_r1_head_attempted_ema  p2_r1_head_attempted_ema  p1_r1_body_landed_ema  \\\n",
       "0                 25.974974                  4.131527               3.184765   \n",
       "1                 20.571429                 45.333333               8.285714   \n",
       "2                 21.014663                 21.444879              11.351906   \n",
       "3                 24.666667                 12.400000               2.333333   \n",
       "4                 34.478522                 38.309402               4.698507   \n",
       "\n",
       "   p2_r1_body_landed_ema  p1_r1_body_attempted_ema  p2_r1_body_attempted_ema  \\\n",
       "0               1.563864                  5.100348                  1.722838   \n",
       "1               8.333333                 10.285714                 10.000000   \n",
       "2               3.692956                 12.464321                  6.984129   \n",
       "3               1.666667                  3.333333                  2.800000   \n",
       "4              10.136752                  6.146630                 14.217582   \n",
       "\n",
       "   p1_r1_leg_landed_ema  p2_r1_leg_landed_ema  p1_r1_leg_attempted_ema  \\\n",
       "0              6.583898              1.804759                 7.770555   \n",
       "1              9.000000              0.000000                10.285714   \n",
       "2              8.664712              1.015749                 9.436950   \n",
       "3              3.000000              4.266667                 3.666667   \n",
       "4              3.883096              6.283272                 4.330378   \n",
       "\n",
       "   p2_r1_leg_attempted_ema  p1_r1_distance_landed_ema  \\\n",
       "0                 1.867382                  14.666789   \n",
       "1                 0.000000                  20.857143   \n",
       "2                 1.392260                  17.914956   \n",
       "3                 4.800000                   8.666667   \n",
       "4                 6.597802                  18.613174   \n",
       "\n",
       "   p2_r1_distance_landed_ema  p1_r1_distance_attempted_ema  \\\n",
       "0                   4.508493                     33.379235   \n",
       "1                  21.000000                     38.857143   \n",
       "2                   8.209010                     29.654936   \n",
       "3                   9.600000                     17.000000   \n",
       "4                  27.526252                     44.685991   \n",
       "\n",
       "   p2_r1_distance_attempted_ema  p1_r1_clinch_landed_ema  \\\n",
       "0                      6.492636                 0.094732   \n",
       "1                     54.000000                 1.714286   \n",
       "2                     18.979856                10.704790   \n",
       "3                     18.600000                 0.666667   \n",
       "4                     59.010256                 0.017265   \n",
       "\n",
       "   p2_r1_clinch_landed_ema  p1_r1_clinch_attempted_ema  \\\n",
       "0                 0.313642                    0.438809   \n",
       "1                 0.000000                    1.714286   \n",
       "2                 2.588939                   13.144673   \n",
       "3                 0.066667                    0.666667   \n",
       "4                 0.007814                    0.267689   \n",
       "\n",
       "   p2_r1_clinch_attempted_ema  p1_r1_ground_landed_ema  \\\n",
       "0                    0.438894                 2.506867   \n",
       "1                    0.666667                 0.000000   \n",
       "2                    3.738738                 0.106549   \n",
       "3                    0.200000                 8.000000   \n",
       "4                    0.015873                 0.001720   \n",
       "\n",
       "   p2_r1_ground_landed_ema  p1_r1_ground_attempted_ema  \\\n",
       "0                 0.538977                    5.027834   \n",
       "1                 0.000000                    0.571429   \n",
       "2                 7.100598                    0.116325   \n",
       "3                 1.200000                   14.000000   \n",
       "4                 0.050794                    0.001850   \n",
       "\n",
       "   p2_r1_ground_attempted_ema  \n",
       "0                    0.790218  \n",
       "1                    0.666667  \n",
       "2                    7.102674  \n",
       "3                    1.200000  \n",
       "4                    0.098657  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import the first CSV file\n",
    "feature_df = pd.read_csv('ufc_features.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Drop the columns\n",
    "columns_to_drop = ['p1_fighter', 'p2_fighter', 'event_date'] #method\n",
    "feature_df = feature_df.drop(columns=columns_to_drop)\n",
    "cols_to_drop = [col for col in feature_df.columns if col.startswith('method_')]\n",
    "feature_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "# Clean all column names\n",
    "def clean_column_name(col):\n",
    "  return col.lower().replace(' ', '_').replace('.', '').replace('-', '_')\n",
    "\n",
    "# Apply to all columns\n",
    "feature_df.columns = [clean_column_name(col) for col in feature_df.columns]\n",
    "\n",
    "# # encode the referee using frequency\n",
    "# ref_counts = feature_df['referee'].value_counts()\n",
    "# feature_df['referee_freq'] = feature_df['referee'].map(ref_counts)\n",
    "# feature_df.drop(columns=['referee'], inplace=True)\n",
    "\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86c2b57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8176, 2, 72)\n",
      "Sample X[0]:\n",
      " [[ 3.50000000e+01  1.88649658e-01 -9.03898155e-01  9.27657219e-02\n",
      "   1.18725739e+00 -5.41339616e-02  1.04903771e-01  1.95423076e-01\n",
      "  -3.08185356e-01 -3.49743081e-01  1.16229940e-01 -4.40363611e-01\n",
      "   5.41652436e-01  7.57168057e-01 -4.13781079e-01 -1.43817431e-01\n",
      "  -2.73728966e-01 -3.82257504e-01 -4.82628892e-01 -1.55251502e-01\n",
      "  -4.66728100e-01 -5.82072121e-01  6.83563961e-02 -1.81819535e-01\n",
      "  -1.77201438e-01 -3.03542762e-01  1.77830293e+00 -4.51245059e-01\n",
      "   1.13359812e-01  8.41983267e-01 -4.22262436e-01 -3.01653048e-01\n",
      "   2.28696957e-01  6.83563961e-02  1.13359812e-01  1.47242305e+00\n",
      "   1.57678689e+00  1.69095464e+00  1.91396128e+00  9.10121235e-01\n",
      "   9.01540302e-01  4.43910978e-01  4.94186940e-01  4.25061863e-01\n",
      "   6.78194083e-01  3.23699837e-01 -2.02358640e-02  1.03749296e+00\n",
      "   1.36353082e+00  9.75063113e-01  1.27441339e+00  2.19638150e+00\n",
      "   2.03950032e+00  1.68887112e+00  1.64845411e+00 -7.40970557e-01\n",
      "  -6.83521842e-01  5.30778344e-01  6.58827787e-01 -8.63603447e-02\n",
      "   2.38142391e-01  1.43877662e-01  2.91666780e-01  1.55310406e+00\n",
      "   1.42305680e+00  7.17847351e-01  5.54820538e-01 -7.30447790e-01\n",
      "  -6.86674595e-01  1.15436246e-01  3.66432136e-01  4.00000000e+00]\n",
      " [ 3.50000000e+01 -1.13920070e+00 -8.67575665e-01  1.72614957e-01\n",
      "  -2.87885444e-01  9.98485713e-01  3.37437269e-02 -2.90171334e-01\n",
      "   1.27243658e-01 -9.00285490e-02  1.27338179e-01  1.03253195e+00\n",
      "   1.33659478e+00 -6.53929418e-01 -1.96090943e-02 -4.21164607e-01\n",
      "  -9.54999185e-01 -1.30449950e-01 -4.05153937e-01 -3.67834519e-01\n",
      "   6.38075848e-01  3.03573193e-01  6.03411693e-01 -1.48342027e-01\n",
      "  -2.31474108e-02 -3.86443745e-01  5.12966494e-01 -4.38570988e-01\n",
      "   2.13347483e+00  4.76684536e-01 -3.27663237e-01 -2.80469034e-01\n",
      "   1.00788257e+00  6.03411693e-01  2.13347483e+00  5.99851804e-01\n",
      "   5.14700303e-01  1.72568872e-01  2.73448052e-01  8.61624994e-01\n",
      "   2.36354409e+00 -6.56039563e-01 -8.78949614e-01 -6.40482315e-01\n",
      "  -9.02737024e-01  1.30237039e+00  1.23192271e+00  1.22727874e-01\n",
      "   2.34351972e-01  1.65785897e+00  1.72400549e+00  4.19451634e-01\n",
      "   3.89147595e-01  8.87042071e-01  6.58693913e-01 -2.18257522e-01\n",
      "  -1.37516665e-01 -4.37481559e-01 -4.34533933e-01 -7.80056747e-01\n",
      "  -9.43242649e-01 -3.29252198e-01 -4.90567240e-01 -1.36810161e-01\n",
      "  -2.58771771e-01 -4.39164714e-01 -7.47697245e-01 -5.73632615e-01\n",
      "  -6.03490347e-01 -3.88345809e-01 -3.91632202e-01  1.00000000e+00]]\n",
      "y shape: (8176,)\n",
      "Sample y: 1\n",
      "Features per fighter (excluding referee): ['height', 'weight', 'reach', 'slpm', 'str_acc', 'sapm', 'str_def', 'td_avg', 'td_acc', 'td_def', 'sub_avg', 'age_at_event', 'age_adjusted_slpm', 'age_adjusted_str_acc', 'age_adjusted_sapm', 'age_adjusted_str_def', 'age_adjusted_td_avg', 'age_adjusted_td_acc', 'age_adjusted_td_def', 'age_adjusted_sub_avg', 'kd_ema', 'sig_str_pct_ema', 'td_pct_ema', 'sub_att_ema', 'rev_ema', 'ctrl_ema', 'r1_kd_ema', 'r1_sig_str_pct_ema', 'r1_td_pct_ema', 'r1_sub_att_ema', 'r1_rev_ema', 'r1_ctrl_ema', 'sig_str_pct_detailed_ema', 'r1_sig_str_pct_detailed_ema', 'sig_str_landed_ema', 'sig_str_attempted_ema', 'total_str_landed_ema', 'total_str_attempted_ema', 'td_landed_ema', 'td_attempted_ema', 'r1_sig_str_landed_ema', 'r1_sig_str_attempted_ema', 'r1_total_str_landed_ema', 'r1_total_str_attempted_ema', 'r1_td_landed_ema', 'r1_td_attempted_ema', 'head_landed_ema', 'head_attempted_ema', 'body_landed_ema', 'body_attempted_ema', 'leg_landed_ema', 'leg_attempted_ema', 'distance_landed_ema', 'distance_attempted_ema', 'clinch_landed_ema', 'clinch_attempted_ema', 'ground_landed_ema', 'ground_attempted_ema', 'r1_head_landed_ema', 'r1_head_attempted_ema', 'r1_body_landed_ema', 'r1_body_attempted_ema', 'r1_leg_landed_ema', 'r1_leg_attempted_ema', 'r1_distance_landed_ema', 'r1_distance_attempted_ema', 'r1_clinch_landed_ema', 'r1_clinch_attempted_ema', 'r1_ground_landed_ema', 'r1_ground_attempted_ema', 'stance']\n",
      "Total features per fighter (including referee): 72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# --- Encode categorical features ---\n",
    "# Encode stances\n",
    "stance_le = LabelEncoder()\n",
    "all_stances = pd.concat([feature_df['p1_stance'], feature_df['p2_stance']])\n",
    "stance_le.fit(all_stances)\n",
    "feature_df['p1_stance'] = stance_le.transform(feature_df['p1_stance'])\n",
    "feature_df['p2_stance'] = stance_le.transform(feature_df['p2_stance'])\n",
    "\n",
    "# Encode referee (new additional categorical feature)\n",
    "referee_le = LabelEncoder()\n",
    "referee_le.fit(feature_df['referee'])\n",
    "feature_df['referee'] = referee_le.transform(feature_df['referee'])\n",
    "\n",
    "# --- Scale numeric features except categorical features ---\n",
    "numeric_feats = [\n",
    "    'height', 'weight', 'reach', 'slpm', 'str_acc', 'sapm', 'str_def',\n",
    "    'td_avg', 'td_acc', 'td_def', 'sub_avg', 'age_at_event',\n",
    "    # Adding fight history metrics\n",
    "    # 'days_since_last_fight', 'wins', 'losses', 'total', 'win_streak',\n",
    "    # Adding age-adjusted metrics\n",
    "    'age_adjusted_slpm', 'age_adjusted_str_acc', 'age_adjusted_sapm',\n",
    "    'age_adjusted_str_def', 'age_adjusted_td_avg', 'age_adjusted_td_acc',\n",
    "    'age_adjusted_td_def', 'age_adjusted_sub_avg',\n",
    "    # Adding EMA metrics\n",
    "    'kd_ema', 'sig_str_pct_ema', 'td_pct_ema', 'sub_att_ema', 'rev_ema',\n",
    "    'ctrl_ema', 'r1_kd_ema', 'r1_sig_str_pct_ema', 'r1_td_pct_ema',\n",
    "    'r1_sub_att_ema', 'r1_rev_ema', 'r1_ctrl_ema',\n",
    "    'sig_str_pct_detailed_ema', 'r1_sig_str_pct_detailed_ema',\n",
    "    'sig_str_landed_ema', 'sig_str_attempted_ema',\n",
    "    'total_str_landed_ema', 'total_str_attempted_ema',\n",
    "    'td_landed_ema', 'td_attempted_ema',\n",
    "    'r1_sig_str_landed_ema', 'r1_sig_str_attempted_ema',\n",
    "    'r1_total_str_landed_ema', 'r1_total_str_attempted_ema',\n",
    "    'r1_td_landed_ema', 'r1_td_attempted_ema',\n",
    "    'head_landed_ema', 'head_attempted_ema',\n",
    "    'body_landed_ema', 'body_attempted_ema',\n",
    "    'leg_landed_ema', 'leg_attempted_ema',\n",
    "    'distance_landed_ema', 'distance_attempted_ema',\n",
    "    'clinch_landed_ema', 'clinch_attempted_ema',\n",
    "    'ground_landed_ema', 'ground_attempted_ema',\n",
    "    'r1_head_landed_ema', 'r1_head_attempted_ema',\n",
    "    'r1_body_landed_ema', 'r1_body_attempted_ema',\n",
    "    'r1_leg_landed_ema', 'r1_leg_attempted_ema',\n",
    "    'r1_distance_landed_ema', 'r1_distance_attempted_ema',\n",
    "    'r1_clinch_landed_ema', 'r1_clinch_attempted_ema',\n",
    "    'r1_ground_landed_ema', 'r1_ground_attempted_ema'\n",
    "]\n",
    "\n",
    "p1_numeric = ['p1_' + f for f in numeric_feats]\n",
    "p2_numeric = ['p2_' + f for f in numeric_feats]\n",
    "\n",
    "# Handle potential NaN values\n",
    "feature_df[p1_numeric + p2_numeric] = feature_df[p1_numeric + p2_numeric].fillna(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "feature_df[p1_numeric + p2_numeric] = scaler.fit_transform(feature_df[p1_numeric + p2_numeric])\n",
    "\n",
    "# --- Prepare features per fighter (including stance) ---\n",
    "features_per_fighter = numeric_feats + ['stance']\n",
    "p1_features = ['p1_' + f for f in features_per_fighter]\n",
    "p2_features = ['p2_' + f for f in features_per_fighter]\n",
    "\n",
    "# --- Structure data for BiLSTM including referee as a global feature ---\n",
    "# Create a sequence of [referee, p1_features] and [referee, p2_features] for each sample\n",
    "X = np.stack([\n",
    "    np.hstack([feature_df[['referee']].values, feature_df[p1_features].values]),\n",
    "    np.hstack([feature_df[['referee']].values, feature_df[p2_features].values])\n",
    "], axis=1)  # shape: (num_samples, 2, 1+num_features_per_fighter)\n",
    "\n",
    "y = feature_df['winner'].values\n",
    "\n",
    "# --- Check the shapes and a sample ---\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Sample X[0]:\\n\", X[0])\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Sample y:\", y[0])\n",
    "print(\"Features per fighter (excluding referee):\", features_per_fighter)\n",
    "print(\"Total features per fighter (including referee):\", len(features_per_fighter) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe46a7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " referee              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " stance (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       "\n",
       " referee_embedding    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,856</span>  referee[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
       "\n",
       " stance_embedding     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>  stance[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
       "\n",
       " lambda_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  referee_embeddin \n",
       "\n",
       " lambda_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  stance_embedding \n",
       "\n",
       " numeric              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " concatenate_6        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lambda_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       lambda_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
       "                                                     numeric[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " bidirectional_10     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">75,264</span>  concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                                                       \n",
       "\n",
       " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  bidirectional_10 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
       "\n",
       " dropout_10           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
       "\n",
       " bidirectional_11     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span>  dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                                                       \n",
       "\n",
       " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  bidirectional_11 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
       "\n",
       " dropout_11           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
       "\n",
       " dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>  dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " referee              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " stance (\u001b[38;5;33mInputLayer\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
       "\n",
       " referee_embedding    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)         \u001b[38;5;34m1,856\u001b[0m  referee[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
       "\n",
       " stance_embedding     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4\u001b[0m)            \u001b[38;5;34m24\u001b[0m  stance[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
       "\n",
       " lambda_12 (\u001b[38;5;33mLambda\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m8\u001b[0m)                \u001b[38;5;34m0\u001b[0m  referee_embeddin \n",
       "\n",
       " lambda_13 (\u001b[38;5;33mLambda\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m4\u001b[0m)                \u001b[38;5;34m0\u001b[0m  stance_embedding \n",
       "\n",
       " numeric              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m70\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " concatenate_6        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m82\u001b[0m)               \u001b[38;5;34m0\u001b[0m  lambda_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
       " (\u001b[38;5;33mConcatenate\u001b[0m)                                       lambda_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
       "                                                     numeric[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " bidirectional_10     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)         \u001b[38;5;34m75,264\u001b[0m  concatenate_6[\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBidirectional\u001b[0m)                                                       \n",
       "\n",
       " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m256\u001b[0m  bidirectional_10 \n",
       " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
       "\n",
       " dropout_10           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)              \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
       " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
       "\n",
       " bidirectional_11     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m41,216\u001b[0m  dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       " (\u001b[38;5;33mBidirectional\u001b[0m)                                                       \n",
       "\n",
       " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m128\u001b[0m  bidirectional_11 \n",
       " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
       "\n",
       " dropout_11           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
       " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
       "\n",
       " dense_6 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                  \u001b[38;5;34m65\u001b[0m  dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,809</span> (464.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,809\u001b[0m (464.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,809</span> (464.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,809\u001b[0m (464.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m 57/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5222 - loss: 1.0755 - precision: 0.5692 - recall: 0.5880"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 74\u001b[39m\n\u001b[32m     60\u001b[39m early_stop = EarlyStopping(\n\u001b[32m     61\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     62\u001b[39m     patience=\u001b[32m10\u001b[39m,\n\u001b[32m     63\u001b[39m     min_delta=\u001b[32m0.001\u001b[39m,\n\u001b[32m     64\u001b[39m     restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     65\u001b[39m )\n\u001b[32m     67\u001b[39m checkpoint = ModelCheckpoint(\n\u001b[32m     68\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbest_model_enhanced.h5\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     69\u001b[39m     save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     70\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     71\u001b[39m     mode=\u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     72\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mreferee_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstance_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_input\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_clean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust if class imbalance exists\u001b[39;49;00m\n\u001b[32m     82\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1498\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1505\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1508\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1509\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1510\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1514\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1515\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Concatenate, LSTM, Bidirectional, Dense, Lambda, Dropout, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# --- CLEAN THE DATA ---\n",
    "X_clean = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "y_clean = y\n",
    "\n",
    "# --- PREPARE INPUTS FOR THE MODEL ---\n",
    "num_samples = X_clean.shape[0]\n",
    "num_features_per_fighter = X_clean.shape[2]  # Should be 77\n",
    "num_referees = int(X_clean[:,:,0].max()) + 1  # Referee is now first feature\n",
    "num_stances = int(X_clean[:,:,-1].max()) + 1  # Stance is last feature\n",
    "num_numeric = num_features_per_fighter - 2    # Exclude referee (0) and stance (-1)\n",
    "\n",
    "# Extract components\n",
    "referee_input = X_clean[:,:,0].astype(int)[..., np.newaxis]  # Shape: (samples, 2, 1)\n",
    "stance_input = X_clean[:,:,-1].astype(int)[..., np.newaxis]  # Shape: (samples, 2, 1)\n",
    "numeric_input = X_clean[:,:,1:-1]  # Shape: (samples, 2, 75)\n",
    "\n",
    "# --- BUILD ENHANCED MODEL ---\n",
    "input_referee = Input(shape=(2, 1), name='referee')\n",
    "input_stance = Input(shape=(2, 1), name='stance')\n",
    "input_numeric = Input(shape=(2, num_numeric), name='numeric')\n",
    "\n",
    "# Embedding layers with regularization\n",
    "emb_referee = Embedding(num_referees, 8, name='referee_embedding', embeddings_regularizer=l2(0.001))(input_referee)\n",
    "emb_stance = Embedding(num_stances, 4, name='stance_embedding', embeddings_regularizer=l2(0.001))(input_stance)\n",
    "\n",
    "# Squeeze embedding dimensions\n",
    "emb_referee = Lambda(lambda x: tf.squeeze(x, axis=2))(emb_referee)\n",
    "emb_stance = Lambda(lambda x: tf.squeeze(x, axis=2))(emb_stance)\n",
    "\n",
    "# Concatenate all features\n",
    "concat = Concatenate(axis=-1)([emb_referee, emb_stance, input_numeric])\n",
    "\n",
    "# Enhanced BiLSTM architecture\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(concat)\n",
    "x = LayerNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Bidirectional(LSTM(32))(x)\n",
    "x = LayerNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001))(x)\n",
    "\n",
    "model = Model(inputs=[input_referee, input_stance, input_numeric], outputs=output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', \n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall')])\n",
    "model.summary()\n",
    "\n",
    "# --- TRAIN WITH IMPROVED CALLBACKS ---\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model_enhanced.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [referee_input, stance_input, numeric_input],\n",
    "    y_clean,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop, checkpoint],\n",
    "    class_weight={0: 1, 1: 1.2}  # Adjust if class imbalance exists\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07fdbcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8176, 2, 14)\n",
      "Sample X[0]:\n",
      " [[ 1.00000000e+02 -5.47078056e-02  1.16358820e+00 -4.21557461e+00\n",
      "  -2.63418383e+00 -4.96570215e+00 -2.73199071e+00 -5.85799874e+00\n",
      "  -1.25596182e+00 -2.08926330e+00 -3.02186878e+00 -8.46211610e-01\n",
      "  -6.11194668e+00  1.00000000e+00]\n",
      " [ 1.00000000e+02  4.13889687e-01  2.07651219e-01 -2.81305510e+00\n",
      "  -2.31454391e+00 -4.06847179e+00 -2.38358504e+00 -4.72717899e+00\n",
      "  -1.13836282e+00 -1.71133563e+00 -2.42421059e+00 -7.44299746e-01\n",
      "  -1.93478120e+00  5.00000000e+00]]\n",
      "y shape: (8176,)\n",
      "Sample y: 1\n",
      "Features per fighter (excluding referee): ['height', 'weight', 'reach', 'slpm', 'str_acc', 'sapm', 'str_def', 'td_avg', 'td_acc', 'td_def', 'sub_avg', 'age_at_event', 'stance']\n",
      "Total features per fighter (including referee): 14\n",
      "\n",
      "--- Time-Based Split Shapes ---\n",
      "X_train_referee shape: (6540, 2, 1)\n",
      "X_train_stance shape: (6540, 2, 1)\n",
      "X_train_numeric shape: (6540, 2, 12)\n",
      "y_train shape: (6540,)\n",
      "X_val_referee shape: (1636, 2, 1)\n",
      "X_val_stance shape: (1636, 2, 1)\n",
      "X_val_numeric shape: (1636, 2, 12)\n",
      "y_val shape: (1636,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " referee              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " stance (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       "\n",
       " referee_embedding    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,856</span>  referee[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
       "\n",
       " stance_embedding     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>  stance[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
       "\n",
       " lambda_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  referee_embeddin \n",
       "\n",
       " lambda_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  stance_embedding \n",
       "\n",
       " numeric              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " concatenate_9        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lambda_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       lambda_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
       "                                                     numeric[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " bidirectional_16     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">45,568</span>  concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                                                       \n",
       "\n",
       " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  bidirectional_16 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
       "\n",
       " dropout_16           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
       "\n",
       " bidirectional_17     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span>  dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                                                       \n",
       "\n",
       " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  bidirectional_17 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
       "\n",
       " dropout_17           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
       "\n",
       " dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>  dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " referee              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " stance (\u001b[38;5;33mInputLayer\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
       "\n",
       " referee_embedding    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)         \u001b[38;5;34m1,856\u001b[0m  referee[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
       "\n",
       " stance_embedding     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4\u001b[0m)            \u001b[38;5;34m24\u001b[0m  stance[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
       "\n",
       " lambda_18 (\u001b[38;5;33mLambda\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m8\u001b[0m)                \u001b[38;5;34m0\u001b[0m  referee_embeddin \n",
       "\n",
       " lambda_19 (\u001b[38;5;33mLambda\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m4\u001b[0m)                \u001b[38;5;34m0\u001b[0m  stance_embedding \n",
       "\n",
       " numeric              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m12\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " concatenate_9        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m24\u001b[0m)               \u001b[38;5;34m0\u001b[0m  lambda_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
       " (\u001b[38;5;33mConcatenate\u001b[0m)                                       lambda_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
       "                                                     numeric[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " bidirectional_16     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)         \u001b[38;5;34m45,568\u001b[0m  concatenate_9[\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBidirectional\u001b[0m)                                                       \n",
       "\n",
       " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m256\u001b[0m  bidirectional_16 \n",
       " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
       "\n",
       " dropout_16           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)              \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
       " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
       "\n",
       " bidirectional_17     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m41,216\u001b[0m  dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       " (\u001b[38;5;33mBidirectional\u001b[0m)                                                       \n",
       "\n",
       " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m128\u001b[0m  bidirectional_17 \n",
       " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
       "\n",
       " dropout_17           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
       " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
       "\n",
       " dense_9 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                  \u001b[38;5;34m65\u001b[0m  dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,113</span> (348.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,113\u001b[0m (348.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,113</span> (348.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,113\u001b[0m (348.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5535 - loss: 1.0274 - precision: 0.6582 - recall: 0.6582"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.5537 - loss: 1.0270 - precision: 0.6583 - recall: 0.6586 - val_accuracy: 0.6002 - val_loss: 0.6965 - val_precision: 0.5944 - val_recall: 0.8904\n",
      "Epoch 2/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6369 - loss: 0.7961 - precision: 0.6940 - recall: 0.7983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6369 - loss: 0.7960 - precision: 0.6940 - recall: 0.7983 - val_accuracy: 0.6412 - val_loss: 0.6378 - val_precision: 0.6333 - val_recall: 0.8465\n",
      "Epoch 3/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6382 - loss: 0.7446 - precision: 0.6908 - recall: 0.7986 - val_accuracy: 0.6302 - val_loss: 0.6428 - val_precision: 0.6141 - val_recall: 0.9057\n",
      "Epoch 4/50\n",
      "\u001b[1m195/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6548 - loss: 0.7001 - precision: 0.7018 - recall: 0.8258"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6549 - loss: 0.6995 - precision: 0.7017 - recall: 0.8261 - val_accuracy: 0.6583 - val_loss: 0.6211 - val_precision: 0.6497 - val_recall: 0.8399\n",
      "Epoch 5/50\n",
      "\u001b[1m204/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6649 - loss: 0.6674 - precision: 0.7048 - recall: 0.8425"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6650 - loss: 0.6673 - precision: 0.7049 - recall: 0.8425 - val_accuracy: 0.6595 - val_loss: 0.6188 - val_precision: 0.6433 - val_recall: 0.8739\n",
      "Epoch 6/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6759 - loss: 0.6555 - precision: 0.7053 - recall: 0.8651 - val_accuracy: 0.6583 - val_loss: 0.6136 - val_precision: 0.6507 - val_recall: 0.8355\n",
      "Epoch 7/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6891 - loss: 0.6297 - precision: 0.7182 - recall: 0.8723 - val_accuracy: 0.6479 - val_loss: 0.6180 - val_precision: 0.6342 - val_recall: 0.8706\n",
      "Epoch 8/50\n",
      "\u001b[1m195/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6839 - loss: 0.6319 - precision: 0.7115 - recall: 0.8743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6838 - loss: 0.6318 - precision: 0.7114 - recall: 0.8741 - val_accuracy: 0.6656 - val_loss: 0.6178 - val_precision: 0.6594 - val_recall: 0.8279\n",
      "Epoch 9/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6887 - loss: 0.6233 - precision: 0.7134 - recall: 0.8753 - val_accuracy: 0.6638 - val_loss: 0.6192 - val_precision: 0.6508 - val_recall: 0.8564\n",
      "Epoch 10/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6980 - loss: 0.5973 - precision: 0.7184 - recall: 0.8829 - val_accuracy: 0.6546 - val_loss: 0.6194 - val_precision: 0.6394 - val_recall: 0.8728\n",
      "Epoch 11/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7014 - loss: 0.5994 - precision: 0.7193 - recall: 0.8943 - val_accuracy: 0.6650 - val_loss: 0.6184 - val_precision: 0.6504 - val_recall: 0.8629\n",
      "Epoch 12/50\n",
      "\u001b[1m194/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7095 - loss: 0.5959 - precision: 0.7279 - recall: 0.8991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7091 - loss: 0.5962 - precision: 0.7275 - recall: 0.8986 - val_accuracy: 0.6681 - val_loss: 0.6159 - val_precision: 0.6614 - val_recall: 0.8289\n",
      "Epoch 13/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7007 - loss: 0.5978 - precision: 0.7201 - recall: 0.8903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7007 - loss: 0.5978 - precision: 0.7201 - recall: 0.8903 - val_accuracy: 0.6754 - val_loss: 0.6134 - val_precision: 0.6715 - val_recall: 0.8180\n",
      "Epoch 14/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7176 - loss: 0.5742 - precision: 0.7403 - recall: 0.8885 - val_accuracy: 0.6656 - val_loss: 0.6162 - val_precision: 0.6594 - val_recall: 0.8279\n",
      "Epoch 15/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7306 - loss: 0.5765 - precision: 0.7438 - recall: 0.8974 - val_accuracy: 0.6583 - val_loss: 0.6213 - val_precision: 0.6465 - val_recall: 0.8542\n",
      "Epoch 16/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7235 - loss: 0.5745 - precision: 0.7345 - recall: 0.9139 - val_accuracy: 0.6620 - val_loss: 0.6180 - val_precision: 0.6584 - val_recall: 0.8180\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Concatenate, LSTM, Bidirectional, Dense, Lambda, Dropout, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Import the first CSV file\n",
    "# IMPORTANT: Keep 'event_date' for time-based validation\n",
    "feature_df = pd.read_csv('ufc_features.csv', parse_dates=['event_date'])\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Drop the columns (excluding event_date now)\n",
    "columns_to_drop = ['p1_fighter', 'p2_fighter'] # 'event_date' is kept\n",
    "feature_df = feature_df.drop(columns=columns_to_drop)\n",
    "cols_to_drop = [col for col in feature_df.columns if col.startswith('method_')]\n",
    "feature_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Clean all column names\n",
    "def clean_column_name(col):\n",
    "  return col.lower().replace(' ', '_').replace('.', '').replace('-', '_')\n",
    "\n",
    "# Apply to all columns\n",
    "feature_df.columns = [clean_column_name(col) for col in feature_df.columns]\n",
    "\n",
    "# Sort by event_date for time-based splitting\n",
    "feature_df = feature_df.sort_values(by='event_date').reset_index(drop=True)\n",
    "\n",
    "# --- Encode categorical features ---\n",
    "# Encode stances\n",
    "stance_le = LabelEncoder()\n",
    "all_stances = pd.concat([feature_df['p1_stance'], feature_df['p2_stance']])\n",
    "stance_le.fit(all_stances)\n",
    "feature_df['p1_stance'] = stance_le.transform(feature_df['p1_stance'])\n",
    "feature_df['p2_stance'] = stance_le.transform(feature_df['p2_stance'])\n",
    "\n",
    "# Encode referee (new additional categorical feature)\n",
    "referee_le = LabelEncoder()\n",
    "referee_le.fit(feature_df['referee'])\n",
    "feature_df['referee'] = referee_le.transform(feature_df['referee'])\n",
    "\n",
    "# --- Scale numeric features except categorical features ---\n",
    "numeric_feats = [\n",
    "    'height', 'weight', 'reach', 'slpm', 'str_acc', 'sapm', 'str_def',\n",
    "    'td_avg', 'td_acc', 'td_def', 'sub_avg', 'age_at_event',\n",
    "    # Adding fight history metrics\n",
    "    # 'days_since_last_fight', 'wins', 'losses', 'total', 'win_streak',\n",
    "    # Adding age-adjusted metrics\n",
    "    # 'age_adjusted_slpm', 'age_adjusted_str_acc', 'age_adjusted_sapm',\n",
    "    # 'age_adjusted_str_def', 'age_adjusted_td_avg', 'age_adjusted_td_acc',\n",
    "    # 'age_adjusted_td_def', 'age_adjusted_sub_avg',\n",
    "    # # Adding EMA metrics\n",
    "    # 'kd_ema', 'sig_str_pct_ema', 'td_pct_ema', 'sub_att_ema', 'rev_ema',\n",
    "    # 'ctrl_ema', 'r1_kd_ema', 'r1_sig_str_pct_ema', 'r1_td_pct_ema',\n",
    "    # 'r1_sub_att_ema', 'r1_rev_ema', 'r1_ctrl_ema',\n",
    "    # 'sig_str_pct_detailed_ema', 'r1_sig_str_pct_detailed_ema',\n",
    "    # 'sig_str_landed_ema', 'sig_str_attempted_ema',\n",
    "    # 'total_str_landed_ema', 'total_str_attempted_ema',\n",
    "    # 'td_landed_ema', 'td_attempted_ema',\n",
    "    # 'r1_sig_str_landed_ema', 'r1_sig_str_attempted_ema',\n",
    "    # 'r1_total_str_landed_ema', 'r1_total_str_attempted_ema',\n",
    "    # 'r1_td_landed_ema', 'r1_td_attempted_ema',\n",
    "    # 'head_landed_ema', 'head_attempted_ema',\n",
    "    # 'body_landed_ema', 'body_attempted_ema',\n",
    "    # 'leg_landed_ema', 'leg_attempted_ema',\n",
    "    # 'distance_landed_ema', 'distance_attempted_ema',\n",
    "    # 'clinch_landed_ema', 'clinch_attempted_ema',\n",
    "    # 'ground_landed_ema', 'ground_attempted_ema',\n",
    "    # 'r1_head_landed_ema', 'r1_head_attempted_ema',\n",
    "    # 'r1_body_landed_ema', 'r1_body_attempted_ema',\n",
    "    # 'r1_leg_landed_ema', 'r1_leg_attempted_ema',\n",
    "    # 'r1_distance_landed_ema', 'r1_distance_attempted_ema',\n",
    "    # 'r1_clinch_landed_ema', 'r1_clinch_attempted_ema',\n",
    "    # 'r1_ground_landed_ema', 'r1_ground_attempted_ema'\n",
    "]\n",
    "\n",
    "p1_numeric = ['p1_' + f for f in numeric_feats]\n",
    "p2_numeric = ['p2_' + f for f in numeric_feats]\n",
    "\n",
    "# Handle potential NaN values\n",
    "feature_df[p1_numeric + p2_numeric] = feature_df[p1_numeric + p2_numeric].fillna(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "feature_df[p1_numeric + p2_numeric] = scaler.fit_transform(feature_df[p1_numeric + p2_numeric])\n",
    "\n",
    "# --- Prepare features per fighter (including stance) ---\n",
    "features_per_fighter = numeric_feats + ['stance']\n",
    "p1_features = ['p1_' + f for f in features_per_fighter]\n",
    "p2_features = ['p2_' + f for f in features_per_fighter]\n",
    "\n",
    "# --- Structure data for BiLSTM including referee as a global feature ---\n",
    "# Create a sequence of [referee, p1_features] and [referee, p2_features] for each sample\n",
    "X = np.stack([\n",
    "    np.hstack([feature_df[['referee']].values, feature_df[p1_features].values]),\n",
    "    np.hstack([feature_df[['referee']].values, feature_df[p2_features].values])\n",
    "], axis=1)  # shape: (num_samples, 2, 1+num_features_per_fighter)\n",
    "\n",
    "y = feature_df['winner'].values\n",
    "\n",
    "# --- Check the shapes and a sample ---\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Sample X[0]:\\n\", X[0])\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Sample y:\", y[0])\n",
    "print(\"Features per fighter (excluding referee):\", features_per_fighter)\n",
    "print(\"Total features per fighter (including referee):\", len(features_per_fighter) + 1)\n",
    "\n",
    "# --- Time-Based Splitting ---\n",
    "# Determine the split point (e.g., 80% for training, 20% for validation)\n",
    "split_point = int(len(feature_df) * 0.8)\n",
    "\n",
    "# Training data\n",
    "X_train_referee = X[:split_point, :, 0].astype(int)[..., np.newaxis]\n",
    "X_train_stance = X[:split_point, :, -1].astype(int)[..., np.newaxis]\n",
    "X_train_numeric = X[:split_point, :, 1:-1]\n",
    "y_train = y[:split_point]\n",
    "\n",
    "# Validation data\n",
    "X_val_referee = X[split_point:, :, 0].astype(int)[..., np.newaxis]\n",
    "X_val_stance = X[split_point:, :, -1].astype(int)[..., np.newaxis]\n",
    "X_val_numeric = X[split_point:, :, 1:-1]\n",
    "y_val = y[split_point:]\n",
    "\n",
    "print(\"\\n--- Time-Based Split Shapes ---\")\n",
    "print(\"X_train_referee shape:\", X_train_referee.shape)\n",
    "print(\"X_train_stance shape:\", X_train_stance.shape)\n",
    "print(\"X_train_numeric shape:\", X_train_numeric.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val_referee shape:\", X_val_referee.shape)\n",
    "print(\"X_val_stance shape:\", X_val_stance.shape)\n",
    "print(\"X_val_numeric shape:\", X_val_numeric.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "\n",
    "# --- CLEAN THE DATA (already done for X, just ensure no NaNs in Y) ---\n",
    "y_train_clean = y_train\n",
    "y_val_clean = y_val\n",
    "\n",
    "# --- PREPARE INPUTS FOR THE MODEL ---\n",
    "# These are already prepared in the time-based splitting section\n",
    "num_features_per_fighter = X.shape[2]\n",
    "num_referees = int(X[:,:,0].max()) + 1\n",
    "num_stances = int(X[:,:,-1].max()) + 1\n",
    "num_numeric = num_features_per_fighter - 2\n",
    "\n",
    "# --- BUILD ENHANCED MODEL (remains the same) ---\n",
    "input_referee = Input(shape=(2, 1), name='referee')\n",
    "input_stance = Input(shape=(2, 1), name='stance')\n",
    "input_numeric = Input(shape=(2, num_numeric), name='numeric')\n",
    "\n",
    "# Embedding layers with regularization\n",
    "emb_referee = Embedding(num_referees, 8, name='referee_embedding', embeddings_regularizer=l2(0.001))(input_referee)\n",
    "emb_stance = Embedding(num_stances, 4, name='stance_embedding', embeddings_regularizer=l2(0.001))(input_stance)\n",
    "\n",
    "# Squeeze embedding dimensions\n",
    "emb_referee = Lambda(lambda x: tf.squeeze(x, axis=2))(emb_referee)\n",
    "emb_stance = Lambda(lambda x: tf.squeeze(x, axis=2))(emb_stance)\n",
    "\n",
    "# Concatenate all features\n",
    "concat = Concatenate(axis=-1)([emb_referee, emb_stance, input_numeric])\n",
    "\n",
    "# Enhanced BiLSTM architecture\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(concat)\n",
    "x = LayerNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Bidirectional(LSTM(32))(x)\n",
    "x = LayerNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001))(x)\n",
    "\n",
    "model = Model(inputs=[input_referee, input_stance, input_numeric], outputs=output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy',\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall')])\n",
    "model.summary()\n",
    "\n",
    "# --- TRAIN WITH IMPROVED CALLBACKS ---\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model_enhanced.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train_referee, X_train_stance, X_train_numeric],\n",
    "    y_train_clean,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=([X_val_referee, X_val_stance, X_val_numeric], y_val_clean), # Use time-based validation data\n",
    "    callbacks=[early_stop, checkpoint],\n",
    "    class_weight={0: 1, 1: 1.2}  # Adjust if class imbalance exists\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

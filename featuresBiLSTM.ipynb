{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8482394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>referee</th>\n",
       "      <th>winner</th>\n",
       "      <th>p1_height</th>\n",
       "      <th>p1_weight</th>\n",
       "      <th>p1_reach</th>\n",
       "      <th>p1_stance</th>\n",
       "      <th>p1_slpm</th>\n",
       "      <th>p1_str_acc</th>\n",
       "      <th>p1_sapm</th>\n",
       "      <th>p1_str_def</th>\n",
       "      <th>p1_td_avg</th>\n",
       "      <th>p1_td_acc</th>\n",
       "      <th>p1_td_def</th>\n",
       "      <th>p1_sub_avg</th>\n",
       "      <th>p2_height</th>\n",
       "      <th>p2_weight</th>\n",
       "      <th>p2_reach</th>\n",
       "      <th>p2_stance</th>\n",
       "      <th>p2_slpm</th>\n",
       "      <th>p2_str_acc</th>\n",
       "      <th>p2_sapm</th>\n",
       "      <th>p2_str_def</th>\n",
       "      <th>p2_td_avg</th>\n",
       "      <th>p2_td_acc</th>\n",
       "      <th>p2_td_def</th>\n",
       "      <th>p2_sub_avg</th>\n",
       "      <th>p1_age_at_event</th>\n",
       "      <th>p2_age_at_event</th>\n",
       "      <th>height_diff</th>\n",
       "      <th>reach_diff</th>\n",
       "      <th>weight_diff</th>\n",
       "      <th>age_diff</th>\n",
       "      <th>slpm_diff</th>\n",
       "      <th>stracc_diff</th>\n",
       "      <th>sapm_diff</th>\n",
       "      <th>strdef_diff</th>\n",
       "      <th>tdavg_diff</th>\n",
       "      <th>tdacc_diff</th>\n",
       "      <th>tddef_diff</th>\n",
       "      <th>subavg_diff</th>\n",
       "      <th>p1_days_since_last_fight</th>\n",
       "      <th>p2_days_since_last_fight</th>\n",
       "      <th>days_since_last_fight_diff</th>\n",
       "      <th>p1_wins</th>\n",
       "      <th>p1_losses</th>\n",
       "      <th>p1_total</th>\n",
       "      <th>p2_wins</th>\n",
       "      <th>p2_losses</th>\n",
       "      <th>p2_total</th>\n",
       "      <th>win_diff</th>\n",
       "      <th>loss_diff</th>\n",
       "      <th>total_diff</th>\n",
       "      <th>p1_win_streak</th>\n",
       "      <th>p2_win_streak</th>\n",
       "      <th>p1_age_adjusted_slpm</th>\n",
       "      <th>p2_age_adjusted_slpm</th>\n",
       "      <th>p1_age_adjusted_str_acc</th>\n",
       "      <th>p2_age_adjusted_str_acc</th>\n",
       "      <th>p1_age_adjusted_sapm</th>\n",
       "      <th>p2_age_adjusted_sapm</th>\n",
       "      <th>p1_age_adjusted_str_def</th>\n",
       "      <th>p2_age_adjusted_str_def</th>\n",
       "      <th>p1_age_adjusted_td_avg</th>\n",
       "      <th>p2_age_adjusted_td_avg</th>\n",
       "      <th>p1_age_adjusted_td_acc</th>\n",
       "      <th>p2_age_adjusted_td_acc</th>\n",
       "      <th>p1_age_adjusted_td_def</th>\n",
       "      <th>p2_age_adjusted_td_def</th>\n",
       "      <th>p1_age_adjusted_sub_avg</th>\n",
       "      <th>p2_age_adjusted_sub_avg</th>\n",
       "      <th>p1_kd_ema</th>\n",
       "      <th>p2_kd_ema</th>\n",
       "      <th>p1_sig_str_pct_ema</th>\n",
       "      <th>p2_sig_str_pct_ema</th>\n",
       "      <th>p1_td_pct_ema</th>\n",
       "      <th>p2_td_pct_ema</th>\n",
       "      <th>p1_sub_att_ema</th>\n",
       "      <th>p2_sub_att_ema</th>\n",
       "      <th>p1_rev_ema</th>\n",
       "      <th>p2_rev_ema</th>\n",
       "      <th>p1_ctrl_ema</th>\n",
       "      <th>p2_ctrl_ema</th>\n",
       "      <th>p1_r1_kd_ema</th>\n",
       "      <th>p2_r1_kd_ema</th>\n",
       "      <th>p1_r1_sig_str_pct_ema</th>\n",
       "      <th>p2_r1_sig_str_pct_ema</th>\n",
       "      <th>p1_r1_td_pct_ema</th>\n",
       "      <th>p2_r1_td_pct_ema</th>\n",
       "      <th>p1_r1_sub_att_ema</th>\n",
       "      <th>p2_r1_sub_att_ema</th>\n",
       "      <th>p1_r1_rev_ema</th>\n",
       "      <th>p2_r1_rev_ema</th>\n",
       "      <th>p1_r1_ctrl_ema</th>\n",
       "      <th>p2_r1_ctrl_ema</th>\n",
       "      <th>p1_sig_str_pct_detailed_ema</th>\n",
       "      <th>p2_sig_str_pct_detailed_ema</th>\n",
       "      <th>p1_r1_sig_str_pct_detailed_ema</th>\n",
       "      <th>p2_r1_sig_str_pct_detailed_ema</th>\n",
       "      <th>p1_sig_str_landed_ema</th>\n",
       "      <th>p2_sig_str_landed_ema</th>\n",
       "      <th>p1_sig_str_attempted_ema</th>\n",
       "      <th>p2_sig_str_attempted_ema</th>\n",
       "      <th>p1_total_str_landed_ema</th>\n",
       "      <th>p2_total_str_landed_ema</th>\n",
       "      <th>p1_total_str_attempted_ema</th>\n",
       "      <th>p2_total_str_attempted_ema</th>\n",
       "      <th>p1_td_landed_ema</th>\n",
       "      <th>p2_td_landed_ema</th>\n",
       "      <th>p1_td_attempted_ema</th>\n",
       "      <th>p2_td_attempted_ema</th>\n",
       "      <th>p1_r1_sig_str_landed_ema</th>\n",
       "      <th>p2_r1_sig_str_landed_ema</th>\n",
       "      <th>p1_r1_sig_str_attempted_ema</th>\n",
       "      <th>p2_r1_sig_str_attempted_ema</th>\n",
       "      <th>p1_r1_total_str_landed_ema</th>\n",
       "      <th>p2_r1_total_str_landed_ema</th>\n",
       "      <th>p1_r1_total_str_attempted_ema</th>\n",
       "      <th>p2_r1_total_str_attempted_ema</th>\n",
       "      <th>p1_r1_td_landed_ema</th>\n",
       "      <th>p2_r1_td_landed_ema</th>\n",
       "      <th>p1_r1_td_attempted_ema</th>\n",
       "      <th>p2_r1_td_attempted_ema</th>\n",
       "      <th>p1_head_landed_ema</th>\n",
       "      <th>p2_head_landed_ema</th>\n",
       "      <th>p1_head_attempted_ema</th>\n",
       "      <th>p2_head_attempted_ema</th>\n",
       "      <th>p1_body_landed_ema</th>\n",
       "      <th>p2_body_landed_ema</th>\n",
       "      <th>p1_body_attempted_ema</th>\n",
       "      <th>p2_body_attempted_ema</th>\n",
       "      <th>p1_leg_landed_ema</th>\n",
       "      <th>p2_leg_landed_ema</th>\n",
       "      <th>p1_leg_attempted_ema</th>\n",
       "      <th>p2_leg_attempted_ema</th>\n",
       "      <th>p1_distance_landed_ema</th>\n",
       "      <th>p2_distance_landed_ema</th>\n",
       "      <th>p1_distance_attempted_ema</th>\n",
       "      <th>p2_distance_attempted_ema</th>\n",
       "      <th>p1_clinch_landed_ema</th>\n",
       "      <th>p2_clinch_landed_ema</th>\n",
       "      <th>p1_clinch_attempted_ema</th>\n",
       "      <th>p2_clinch_attempted_ema</th>\n",
       "      <th>p1_ground_landed_ema</th>\n",
       "      <th>p2_ground_landed_ema</th>\n",
       "      <th>p1_ground_attempted_ema</th>\n",
       "      <th>p2_ground_attempted_ema</th>\n",
       "      <th>p1_r1_head_landed_ema</th>\n",
       "      <th>p2_r1_head_landed_ema</th>\n",
       "      <th>p1_r1_head_attempted_ema</th>\n",
       "      <th>p2_r1_head_attempted_ema</th>\n",
       "      <th>p1_r1_body_landed_ema</th>\n",
       "      <th>p2_r1_body_landed_ema</th>\n",
       "      <th>p1_r1_body_attempted_ema</th>\n",
       "      <th>p2_r1_body_attempted_ema</th>\n",
       "      <th>p1_r1_leg_landed_ema</th>\n",
       "      <th>p2_r1_leg_landed_ema</th>\n",
       "      <th>p1_r1_leg_attempted_ema</th>\n",
       "      <th>p2_r1_leg_attempted_ema</th>\n",
       "      <th>p1_r1_distance_landed_ema</th>\n",
       "      <th>p2_r1_distance_landed_ema</th>\n",
       "      <th>p1_r1_distance_attempted_ema</th>\n",
       "      <th>p2_r1_distance_attempted_ema</th>\n",
       "      <th>p1_r1_clinch_landed_ema</th>\n",
       "      <th>p2_r1_clinch_landed_ema</th>\n",
       "      <th>p1_r1_clinch_attempted_ema</th>\n",
       "      <th>p2_r1_clinch_attempted_ema</th>\n",
       "      <th>p1_r1_ground_landed_ema</th>\n",
       "      <th>p2_r1_ground_landed_ema</th>\n",
       "      <th>p1_r1_ground_attempted_ema</th>\n",
       "      <th>p2_r1_ground_attempted_ema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dan Miragliotta</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Switch</td>\n",
       "      <td>5.02</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.4</td>\n",
       "      <td>33.034908</td>\n",
       "      <td>37.374401</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.339493</td>\n",
       "      <td>2.11</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.151960</td>\n",
       "      <td>0.077861</td>\n",
       "      <td>0.013319</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.104738</td>\n",
       "      <td>0.094985</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>0.013111</td>\n",
       "      <td>0.036023</td>\n",
       "      <td>0.043345</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.009097</td>\n",
       "      <td>0.019071</td>\n",
       "      <td>0.016054</td>\n",
       "      <td>0.009081</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.299520</td>\n",
       "      <td>0.427808</td>\n",
       "      <td>0.499030</td>\n",
       "      <td>0.295141</td>\n",
       "      <td>0.250166</td>\n",
       "      <td>0.266130</td>\n",
       "      <td>0.319192</td>\n",
       "      <td>0.032290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>369.136117</td>\n",
       "      <td>174.851985</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.434544</td>\n",
       "      <td>0.846666</td>\n",
       "      <td>0.664548</td>\n",
       "      <td>0.467068</td>\n",
       "      <td>0.016114</td>\n",
       "      <td>0.037895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.763841</td>\n",
       "      <td>98.073334</td>\n",
       "      <td>0.427808</td>\n",
       "      <td>0.499030</td>\n",
       "      <td>0.434544</td>\n",
       "      <td>0.846666</td>\n",
       "      <td>73.462980</td>\n",
       "      <td>44.916534</td>\n",
       "      <td>168.352377</td>\n",
       "      <td>94.296907</td>\n",
       "      <td>112.881890</td>\n",
       "      <td>50.330579</td>\n",
       "      <td>222.104682</td>\n",
       "      <td>99.836223</td>\n",
       "      <td>2.220167</td>\n",
       "      <td>1.953972</td>\n",
       "      <td>5.331929</td>\n",
       "      <td>8.821761</td>\n",
       "      <td>17.268388</td>\n",
       "      <td>5.361112</td>\n",
       "      <td>38.845877</td>\n",
       "      <td>7.721747</td>\n",
       "      <td>24.855216</td>\n",
       "      <td>8.417673</td>\n",
       "      <td>50.872063</td>\n",
       "      <td>10.778392</td>\n",
       "      <td>0.625343</td>\n",
       "      <td>1.141289</td>\n",
       "      <td>1.002075</td>\n",
       "      <td>2.395547</td>\n",
       "      <td>40.424648</td>\n",
       "      <td>20.674029</td>\n",
       "      <td>123.293902</td>\n",
       "      <td>61.038605</td>\n",
       "      <td>13.657023</td>\n",
       "      <td>17.218732</td>\n",
       "      <td>22.233046</td>\n",
       "      <td>24.789088</td>\n",
       "      <td>19.381310</td>\n",
       "      <td>7.023773</td>\n",
       "      <td>22.825429</td>\n",
       "      <td>8.469213</td>\n",
       "      <td>64.249344</td>\n",
       "      <td>40.422319</td>\n",
       "      <td>153.012147</td>\n",
       "      <td>87.092312</td>\n",
       "      <td>0.629677</td>\n",
       "      <td>2.975746</td>\n",
       "      <td>1.600867</td>\n",
       "      <td>4.961387</td>\n",
       "      <td>8.583959</td>\n",
       "      <td>1.518469</td>\n",
       "      <td>13.739364</td>\n",
       "      <td>2.243207</td>\n",
       "      <td>7.499725</td>\n",
       "      <td>1.992489</td>\n",
       "      <td>25.974974</td>\n",
       "      <td>4.131527</td>\n",
       "      <td>3.184765</td>\n",
       "      <td>1.563864</td>\n",
       "      <td>5.100348</td>\n",
       "      <td>1.722838</td>\n",
       "      <td>6.583898</td>\n",
       "      <td>1.804759</td>\n",
       "      <td>7.770555</td>\n",
       "      <td>1.867382</td>\n",
       "      <td>14.666789</td>\n",
       "      <td>4.508493</td>\n",
       "      <td>33.379235</td>\n",
       "      <td>6.492636</td>\n",
       "      <td>0.094732</td>\n",
       "      <td>0.313642</td>\n",
       "      <td>0.438809</td>\n",
       "      <td>0.438894</td>\n",
       "      <td>2.506867</td>\n",
       "      <td>0.538977</td>\n",
       "      <td>5.027834</td>\n",
       "      <td>0.790218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tyrone Roberts</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.35</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.632444</td>\n",
       "      <td>33.541410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.908966</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-2.95</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114610</td>\n",
       "      <td>0.090038</td>\n",
       "      <td>0.015322</td>\n",
       "      <td>0.010435</td>\n",
       "      <td>0.078756</td>\n",
       "      <td>0.164573</td>\n",
       "      <td>0.015935</td>\n",
       "      <td>0.013416</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>0.050684</td>\n",
       "      <td>0.030644</td>\n",
       "      <td>0.006857</td>\n",
       "      <td>0.012871</td>\n",
       "      <td>0.029814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.567143</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.393333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>168.571429</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.571429</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>0.567143</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.545714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>47.285714</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>84.142857</td>\n",
       "      <td>126.333333</td>\n",
       "      <td>63.571429</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>102.142857</td>\n",
       "      <td>135.666667</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>41.142857</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>23.714286</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>43.142857</td>\n",
       "      <td>57.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.142857</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>102.333333</td>\n",
       "      <td>13.857143</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>12.285714</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.142857</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>30.714286</td>\n",
       "      <td>44.333333</td>\n",
       "      <td>61.571429</td>\n",
       "      <td>119.666667</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>16.857143</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>20.571429</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>10.285714</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.857143</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>38.857143</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kevin MacDonald</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>4.42</td>\n",
       "      <td>0.58</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.3</td>\n",
       "      <td>35.474333</td>\n",
       "      <td>38.707734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.233402</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>266.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>-252.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124597</td>\n",
       "      <td>0.067687</td>\n",
       "      <td>0.016350</td>\n",
       "      <td>0.011626</td>\n",
       "      <td>0.087951</td>\n",
       "      <td>0.076987</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>0.013176</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.052186</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>0.008009</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.033585</td>\n",
       "      <td>0.500489</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.625855</td>\n",
       "      <td>0.665875</td>\n",
       "      <td>0.586522</td>\n",
       "      <td>0.461598</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.528751</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>124.804497</td>\n",
       "      <td>415.556831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.668456</td>\n",
       "      <td>0.667600</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.621714</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>53.725318</td>\n",
       "      <td>180.858625</td>\n",
       "      <td>0.625855</td>\n",
       "      <td>0.665875</td>\n",
       "      <td>0.668456</td>\n",
       "      <td>0.667600</td>\n",
       "      <td>77.987292</td>\n",
       "      <td>57.932243</td>\n",
       "      <td>119.926686</td>\n",
       "      <td>105.343182</td>\n",
       "      <td>133.727273</td>\n",
       "      <td>121.433525</td>\n",
       "      <td>187.241447</td>\n",
       "      <td>180.664144</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>2.365645</td>\n",
       "      <td>0.054741</td>\n",
       "      <td>5.704920</td>\n",
       "      <td>28.726295</td>\n",
       "      <td>17.898547</td>\n",
       "      <td>42.915934</td>\n",
       "      <td>29.821267</td>\n",
       "      <td>48.221896</td>\n",
       "      <td>39.323282</td>\n",
       "      <td>65.002933</td>\n",
       "      <td>55.751557</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.595288</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>1.565743</td>\n",
       "      <td>21.695015</td>\n",
       "      <td>40.738005</td>\n",
       "      <td>52.746823</td>\n",
       "      <td>78.202661</td>\n",
       "      <td>32.728250</td>\n",
       "      <td>14.005860</td>\n",
       "      <td>40.544477</td>\n",
       "      <td>22.364058</td>\n",
       "      <td>23.564027</td>\n",
       "      <td>3.188377</td>\n",
       "      <td>26.635386</td>\n",
       "      <td>4.776462</td>\n",
       "      <td>48.708700</td>\n",
       "      <td>35.804908</td>\n",
       "      <td>84.446725</td>\n",
       "      <td>78.584300</td>\n",
       "      <td>28.599218</td>\n",
       "      <td>6.882920</td>\n",
       "      <td>34.564027</td>\n",
       "      <td>9.668172</td>\n",
       "      <td>0.679374</td>\n",
       "      <td>15.244415</td>\n",
       "      <td>0.915934</td>\n",
       "      <td>17.090709</td>\n",
       "      <td>8.709677</td>\n",
       "      <td>13.189843</td>\n",
       "      <td>21.014663</td>\n",
       "      <td>21.444879</td>\n",
       "      <td>11.351906</td>\n",
       "      <td>3.692956</td>\n",
       "      <td>12.464321</td>\n",
       "      <td>6.984129</td>\n",
       "      <td>8.664712</td>\n",
       "      <td>1.015749</td>\n",
       "      <td>9.436950</td>\n",
       "      <td>1.392260</td>\n",
       "      <td>17.914956</td>\n",
       "      <td>8.209010</td>\n",
       "      <td>29.654936</td>\n",
       "      <td>18.979856</td>\n",
       "      <td>10.704790</td>\n",
       "      <td>2.588939</td>\n",
       "      <td>13.144673</td>\n",
       "      <td>3.738738</td>\n",
       "      <td>0.106549</td>\n",
       "      <td>7.100598</td>\n",
       "      <td>0.116325</td>\n",
       "      <td>7.102674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mike Beltran</td>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.38</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.6</td>\n",
       "      <td>34.652977</td>\n",
       "      <td>29.300479</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.352498</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>3.28</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>105.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.094653</td>\n",
       "      <td>0.090442</td>\n",
       "      <td>0.016449</td>\n",
       "      <td>0.021501</td>\n",
       "      <td>0.077627</td>\n",
       "      <td>0.063480</td>\n",
       "      <td>0.010966</td>\n",
       "      <td>0.021843</td>\n",
       "      <td>0.198829</td>\n",
       "      <td>0.123206</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.028858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057715</td>\n",
       "      <td>0.122865</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.608667</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>206.333333</td>\n",
       "      <td>128.933333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.571333</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>151.333333</td>\n",
       "      <td>80.933333</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.608667</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.571333</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>31.933333</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>50.400000</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>41.933333</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>62.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>10.866667</td>\n",
       "      <td>31.666667</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>16.066667</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>25.733333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>31.066667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.533333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.066667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>10.133333</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>47.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.266667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kevin MacDonald</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Orthodox</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Southpaw</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.1</td>\n",
       "      <td>38.600958</td>\n",
       "      <td>38.338125</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262834</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>-91.0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124349</td>\n",
       "      <td>0.195628</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.012781</td>\n",
       "      <td>0.119427</td>\n",
       "      <td>0.142678</td>\n",
       "      <td>0.015803</td>\n",
       "      <td>0.015129</td>\n",
       "      <td>0.014507</td>\n",
       "      <td>0.015389</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.014868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.568214</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.409565</td>\n",
       "      <td>0.457250</td>\n",
       "      <td>0.306089</td>\n",
       "      <td>0.879828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>58.837074</td>\n",
       "      <td>33.627839</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.405490</td>\n",
       "      <td>0.444244</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.003412</td>\n",
       "      <td>1.010745</td>\n",
       "      <td>0.409565</td>\n",
       "      <td>0.457250</td>\n",
       "      <td>0.405490</td>\n",
       "      <td>0.444244</td>\n",
       "      <td>63.825189</td>\n",
       "      <td>104.030037</td>\n",
       "      <td>152.684444</td>\n",
       "      <td>215.924054</td>\n",
       "      <td>64.124443</td>\n",
       "      <td>107.503541</td>\n",
       "      <td>152.983705</td>\n",
       "      <td>220.185348</td>\n",
       "      <td>0.549813</td>\n",
       "      <td>0.500611</td>\n",
       "      <td>1.518626</td>\n",
       "      <td>0.570940</td>\n",
       "      <td>18.632159</td>\n",
       "      <td>27.584860</td>\n",
       "      <td>44.955530</td>\n",
       "      <td>59.124786</td>\n",
       "      <td>18.632432</td>\n",
       "      <td>27.745055</td>\n",
       "      <td>44.955805</td>\n",
       "      <td>59.538950</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.062515</td>\n",
       "      <td>44.064673</td>\n",
       "      <td>48.864225</td>\n",
       "      <td>125.755292</td>\n",
       "      <td>145.810745</td>\n",
       "      <td>8.460826</td>\n",
       "      <td>38.950672</td>\n",
       "      <td>13.522847</td>\n",
       "      <td>52.964347</td>\n",
       "      <td>11.299691</td>\n",
       "      <td>16.215140</td>\n",
       "      <td>13.406304</td>\n",
       "      <td>17.148962</td>\n",
       "      <td>61.410415</td>\n",
       "      <td>100.666911</td>\n",
       "      <td>146.797878</td>\n",
       "      <td>212.363614</td>\n",
       "      <td>0.302455</td>\n",
       "      <td>3.201954</td>\n",
       "      <td>0.677917</td>\n",
       "      <td>3.210745</td>\n",
       "      <td>2.112320</td>\n",
       "      <td>0.161172</td>\n",
       "      <td>5.208649</td>\n",
       "      <td>0.349695</td>\n",
       "      <td>10.050556</td>\n",
       "      <td>11.164835</td>\n",
       "      <td>34.478522</td>\n",
       "      <td>38.309402</td>\n",
       "      <td>4.698507</td>\n",
       "      <td>10.136752</td>\n",
       "      <td>6.146630</td>\n",
       "      <td>14.217582</td>\n",
       "      <td>3.883096</td>\n",
       "      <td>6.283272</td>\n",
       "      <td>4.330378</td>\n",
       "      <td>6.597802</td>\n",
       "      <td>18.613174</td>\n",
       "      <td>27.526252</td>\n",
       "      <td>44.685991</td>\n",
       "      <td>59.010256</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>0.267689</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.050794</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.098657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           referee  winner  p1_height  p1_weight  p1_reach p1_stance  p1_slpm  \\\n",
       "0  Dan Miragliotta       1       71.0      135.0      70.0    Switch     5.02   \n",
       "1   Tyrone Roberts       0       67.0      135.0      69.0  Orthodox     3.74   \n",
       "2  Kevin MacDonald       1       66.0      135.0      68.0  Orthodox     4.42   \n",
       "3     Mike Beltran       1       76.0      185.0      78.0  Southpaw     3.28   \n",
       "4  Kevin MacDonald       0       72.0      170.0      73.0  Orthodox     4.80   \n",
       "\n",
       "   p1_str_acc  p1_sapm  p1_str_def  p1_td_avg  p1_td_acc  p1_td_def  \\\n",
       "0        0.44     3.46        0.56       1.19       0.32       0.63   \n",
       "1        0.50     2.57        0.52       0.78       1.00       0.42   \n",
       "2        0.58     3.12        0.50       0.97       0.53       0.42   \n",
       "3        0.57     2.69        0.38       6.89       0.46       1.00   \n",
       "4        0.41     4.61        0.61       0.56       0.32       0.71   \n",
       "\n",
       "   p1_sub_avg  p2_height  p2_weight  p2_reach p2_stance  p2_slpm  p2_str_acc  \\\n",
       "0         0.3       65.0      135.0      68.0  Orthodox     2.91        0.54   \n",
       "1         0.0       66.0      135.0      70.0  Orthodox     3.02        0.35   \n",
       "2         0.1       66.0      135.0      65.0  Orthodox     2.62        0.45   \n",
       "3         2.0       73.0      185.0      76.0  Southpaw     2.65        0.63   \n",
       "4         0.0       73.0      170.0      74.0  Southpaw     7.50        0.49   \n",
       "\n",
       "   p2_sapm  p2_str_def  p2_td_avg  p2_td_acc  p2_td_def  p2_sub_avg  \\\n",
       "0     3.55        0.49       1.62       0.34       0.60         1.4   \n",
       "1     5.52        0.45       1.70       0.23       1.00         0.0   \n",
       "2     2.98        0.51       2.02       0.31       0.55         1.3   \n",
       "3     1.86        0.64       3.61       0.50       0.00         3.6   \n",
       "4     5.47        0.58       0.59       0.54       0.57         0.1   \n",
       "\n",
       "   p1_age_at_event  p2_age_at_event  height_diff  reach_diff  weight_diff  \\\n",
       "0        33.034908        37.374401          6.0         2.0          0.0   \n",
       "1        32.632444        33.541410          1.0        -1.0          0.0   \n",
       "2        35.474333        38.707734          0.0         3.0          0.0   \n",
       "3        34.652977        29.300479          3.0         2.0          0.0   \n",
       "4        38.600958        38.338125         -1.0        -1.0          0.0   \n",
       "\n",
       "   age_diff  slpm_diff  stracc_diff  sapm_diff  strdef_diff  tdavg_diff  \\\n",
       "0 -4.339493       2.11        -0.10      -0.09         0.07       -0.43   \n",
       "1 -0.908966       0.72         0.15      -2.95         0.07       -0.92   \n",
       "2 -3.233402       1.80         0.13       0.14        -0.01       -1.05   \n",
       "3  5.352498       0.63        -0.06       0.83        -0.26        3.28   \n",
       "4  0.262834      -2.70        -0.08      -0.86         0.03       -0.03   \n",
       "\n",
       "   tdacc_diff  tddef_diff  subavg_diff  p1_days_since_last_fight  \\\n",
       "0       -0.02        0.03         -1.1                     273.0   \n",
       "1        0.77       -0.58          0.0                     175.0   \n",
       "2        0.22       -0.13         -1.2                     266.0   \n",
       "3       -0.04        1.00         -1.6                     105.0   \n",
       "4       -0.22        0.14         -0.1                     112.0   \n",
       "\n",
       "   p2_days_since_last_fight  days_since_last_fight_diff  p1_wins  p1_losses  \\\n",
       "0                     161.0                       112.0       10          4   \n",
       "1                     161.0                        14.0        2          1   \n",
       "2                     518.0                      -252.0        5          5   \n",
       "3                     168.0                       -63.0        2          0   \n",
       "4                     203.0                       -91.0       12          7   \n",
       "\n",
       "   p1_total  p2_wins  p2_losses  p2_total  win_diff  loss_diff  total_diff  \\\n",
       "0        14       13          5        18        -3         -1          -4   \n",
       "1         3        0          2         2         2         -1           1   \n",
       "2        10        7          6        13        -2         -1          -3   \n",
       "3         2        4          0         4        -2          0          -2   \n",
       "4        19        8          4        12         4          3           7   \n",
       "\n",
       "   p1_win_streak  p2_win_streak  p1_age_adjusted_slpm  p2_age_adjusted_slpm  \\\n",
       "0              0              0              0.151960              0.077861   \n",
       "1              1              0              0.114610              0.090038   \n",
       "2              1              1              0.124597              0.067687   \n",
       "3              2              4              0.094653              0.090442   \n",
       "4              1              1              0.124349              0.195628   \n",
       "\n",
       "   p1_age_adjusted_str_acc  p2_age_adjusted_str_acc  p1_age_adjusted_sapm  \\\n",
       "0                 0.013319                 0.014448              0.104738   \n",
       "1                 0.015322                 0.010435              0.078756   \n",
       "2                 0.016350                 0.011626              0.087951   \n",
       "3                 0.016449                 0.021501              0.077627   \n",
       "4                 0.010621                 0.012781              0.119427   \n",
       "\n",
       "   p2_age_adjusted_sapm  p1_age_adjusted_str_def  p2_age_adjusted_str_def  \\\n",
       "0              0.094985                 0.016952                 0.013111   \n",
       "1              0.164573                 0.015935                 0.013416   \n",
       "2              0.076987                 0.014095                 0.013176   \n",
       "3              0.063480                 0.010966                 0.021843   \n",
       "4              0.142678                 0.015803                 0.015129   \n",
       "\n",
       "   p1_age_adjusted_td_avg  p2_age_adjusted_td_avg  p1_age_adjusted_td_acc  \\\n",
       "0                0.036023                0.043345                0.009687   \n",
       "1                0.023903                0.050684                0.030644   \n",
       "2                0.027344                0.052186                0.014940   \n",
       "3                0.198829                0.123206                0.013274   \n",
       "4                0.014507                0.015389                0.008290   \n",
       "\n",
       "   p2_age_adjusted_td_acc  p1_age_adjusted_td_def  p2_age_adjusted_td_def  \\\n",
       "0                0.009097                0.019071                0.016054   \n",
       "1                0.006857                0.012871                0.029814   \n",
       "2                0.008009                0.011840                0.014209   \n",
       "3                0.017065                0.028858                0.000000   \n",
       "4                0.014085                0.018393                0.014868   \n",
       "\n",
       "   p1_age_adjusted_sub_avg  p2_age_adjusted_sub_avg  p1_kd_ema  p2_kd_ema  \\\n",
       "0                 0.009081                 0.037459   0.012025   0.299520   \n",
       "1                 0.000000                 0.000000   0.000000   0.000000   \n",
       "2                 0.002819                 0.033585   0.500489   0.003907   \n",
       "3                 0.057715                 0.122865   0.333333   0.133333   \n",
       "4                 0.000000                 0.002608   0.568214   0.003175   \n",
       "\n",
       "   p1_sig_str_pct_ema  p2_sig_str_pct_ema  p1_td_pct_ema  p2_td_pct_ema  \\\n",
       "0            0.427808            0.499030       0.295141       0.250166   \n",
       "1            0.567143            0.350000       1.000000       0.393333   \n",
       "2            0.625855            0.665875       0.586522       0.461598   \n",
       "3            0.570000            0.608667       0.793333       0.321429   \n",
       "4            0.409565            0.457250       0.306089       0.879828   \n",
       "\n",
       "   p1_sub_att_ema  p2_sub_att_ema  p1_rev_ema  p2_rev_ema  p1_ctrl_ema  \\\n",
       "0        0.266130        0.319192    0.032290    0.000000   369.136117   \n",
       "1        0.000000        0.000000    0.714286    0.000000   168.571429   \n",
       "2        0.001955        0.528751    0.007820    0.002198   124.804497   \n",
       "3        1.000000        0.666667    0.000000    0.000000   206.333333   \n",
       "4        0.000000        0.000244    0.000000    0.015629    58.837074   \n",
       "\n",
       "   p2_ctrl_ema  p1_r1_kd_ema  p2_r1_kd_ema  p1_r1_sig_str_pct_ema  \\\n",
       "0   174.851985      0.008057      0.001953               0.434544   \n",
       "1    86.333333      0.000000      0.000000               0.545714   \n",
       "2   415.556831      0.000000      0.003907               0.668456   \n",
       "3   128.933333      0.333333      0.133333               0.553333   \n",
       "4    33.627839      0.000584      0.003175               0.405490   \n",
       "\n",
       "   p2_r1_sig_str_pct_ema  p1_r1_td_pct_ema  p2_r1_td_pct_ema  \\\n",
       "0               0.846666          0.664548          0.467068   \n",
       "1               0.333333               NaN          0.660000   \n",
       "2               0.667600          0.750000          0.621714   \n",
       "3               0.571333          0.776667          0.321429   \n",
       "4               0.444244          0.333333          0.000000   \n",
       "\n",
       "   p1_r1_sub_att_ema  p2_r1_sub_att_ema  p1_r1_rev_ema  p2_r1_rev_ema  \\\n",
       "0           0.016114           0.037895       0.000000       0.000000   \n",
       "1           0.000000           0.000000       0.571429       0.000000   \n",
       "2           0.001955           0.000000       0.007820       0.000244   \n",
       "3           0.666667           0.133333       0.000000       0.000000   \n",
       "4           0.000000           0.000000       0.000000       0.000000   \n",
       "\n",
       "   p1_r1_ctrl_ema  p2_r1_ctrl_ema  p1_sig_str_pct_detailed_ema  \\\n",
       "0       62.763841       98.073334                     0.427808   \n",
       "1       52.571429       14.666667                     0.567143   \n",
       "2       53.725318      180.858625                     0.625855   \n",
       "3      151.333333       80.933333                     0.570000   \n",
       "4        2.003412        1.010745                     0.409565   \n",
       "\n",
       "   p2_sig_str_pct_detailed_ema  p1_r1_sig_str_pct_detailed_ema  \\\n",
       "0                     0.499030                        0.434544   \n",
       "1                     0.350000                        0.545714   \n",
       "2                     0.665875                        0.668456   \n",
       "3                     0.608667                        0.553333   \n",
       "4                     0.457250                        0.405490   \n",
       "\n",
       "   p2_r1_sig_str_pct_detailed_ema  p1_sig_str_landed_ema  \\\n",
       "0                        0.846666              73.462980   \n",
       "1                        0.333333              47.285714   \n",
       "2                        0.667600              77.987292   \n",
       "3                        0.571333              20.666667   \n",
       "4                        0.444244              63.825189   \n",
       "\n",
       "   p2_sig_str_landed_ema  p1_sig_str_attempted_ema  p2_sig_str_attempted_ema  \\\n",
       "0              44.916534                168.352377                 94.296907   \n",
       "1              48.000000                 84.142857                126.333333   \n",
       "2              57.932243                119.926686                105.343182   \n",
       "3              31.933333                 36.000000                 50.400000   \n",
       "4             104.030037                152.684444                215.924054   \n",
       "\n",
       "   p1_total_str_landed_ema  p2_total_str_landed_ema  \\\n",
       "0               112.881890                50.330579   \n",
       "1                63.571429                56.000000   \n",
       "2               133.727273               121.433525   \n",
       "3                44.666667                41.933333   \n",
       "4                64.124443               107.503541   \n",
       "\n",
       "   p1_total_str_attempted_ema  p2_total_str_attempted_ema  p1_td_landed_ema  \\\n",
       "0                  222.104682                   99.836223          2.220167   \n",
       "1                  102.142857                  135.666667          1.142857   \n",
       "2                  187.241447                  180.664144          0.030303   \n",
       "3                   61.333333                   62.800000          3.000000   \n",
       "4                  152.983705                  220.185348          0.549813   \n",
       "\n",
       "   p2_td_landed_ema  p1_td_attempted_ema  p2_td_attempted_ema  \\\n",
       "0          1.953972             5.331929             8.821761   \n",
       "1          1.333333             1.142857             5.000000   \n",
       "2          2.365645             0.054741             5.704920   \n",
       "3          0.866667             5.666667             2.000000   \n",
       "4          0.500611             1.518626             0.570940   \n",
       "\n",
       "   p1_r1_sig_str_landed_ema  p2_r1_sig_str_landed_ema  \\\n",
       "0                 17.268388                  5.361112   \n",
       "1                 22.571429                 21.000000   \n",
       "2                 28.726295                 17.898547   \n",
       "3                 17.333333                 10.866667   \n",
       "4                 18.632159                 27.584860   \n",
       "\n",
       "   p1_r1_sig_str_attempted_ema  p2_r1_sig_str_attempted_ema  \\\n",
       "0                    38.845877                     7.721747   \n",
       "1                    41.142857                    55.333333   \n",
       "2                    42.915934                    29.821267   \n",
       "3                    31.666667                    20.000000   \n",
       "4                    44.955530                    59.124786   \n",
       "\n",
       "   p1_r1_total_str_landed_ema  p2_r1_total_str_landed_ema  \\\n",
       "0                   24.855216                    8.417673   \n",
       "1                   23.714286                   22.333333   \n",
       "2                   48.221896                   39.323282   \n",
       "3                   28.333333                   16.066667   \n",
       "4                   18.632432                   27.745055   \n",
       "\n",
       "   p1_r1_total_str_attempted_ema  p2_r1_total_str_attempted_ema  \\\n",
       "0                      50.872063                      10.778392   \n",
       "1                      43.142857                      57.333333   \n",
       "2                      65.002933                      55.751557   \n",
       "3                      43.000000                      25.733333   \n",
       "4                      44.955805                      59.538950   \n",
       "\n",
       "   p1_r1_td_landed_ema  p2_r1_td_landed_ema  p1_r1_td_attempted_ema  \\\n",
       "0             0.625343             1.141289                1.002075   \n",
       "1             0.000000             0.666667                0.000000   \n",
       "2             0.008798             0.595288                0.015640   \n",
       "3             2.000000             0.600000                3.333333   \n",
       "4             0.000008             0.000000                0.000053   \n",
       "\n",
       "   p2_r1_td_attempted_ema  p1_head_landed_ema  p2_head_landed_ema  \\\n",
       "0                2.395547           40.424648           20.674029   \n",
       "1                1.000000           21.142857           28.000000   \n",
       "2                1.565743           21.695015           40.738005   \n",
       "3                1.466667           13.666667           15.333333   \n",
       "4                0.062515           44.064673           48.864225   \n",
       "\n",
       "   p1_head_attempted_ema  p2_head_attempted_ema  p1_body_landed_ema  \\\n",
       "0             123.293902              61.038605           13.657023   \n",
       "1              52.000000             102.333333           13.857143   \n",
       "2              52.746823              78.202661           32.728250   \n",
       "3              27.333333              31.066667            4.000000   \n",
       "4             125.755292             145.810745            8.460826   \n",
       "\n",
       "   p2_body_landed_ema  p1_body_attempted_ema  p2_body_attempted_ema  \\\n",
       "0           17.218732              22.233046              24.789088   \n",
       "1           17.000000              18.000000              20.666667   \n",
       "2           14.005860              40.544477              22.364058   \n",
       "3            7.533333               5.000000               9.200000   \n",
       "4           38.950672              13.522847              52.964347   \n",
       "\n",
       "   p1_leg_landed_ema  p2_leg_landed_ema  p1_leg_attempted_ema  \\\n",
       "0          19.381310           7.023773             22.825429   \n",
       "1          12.285714           3.000000             14.142857   \n",
       "2          23.564027           3.188377             26.635386   \n",
       "3           3.000000           9.066667              3.666667   \n",
       "4          11.299691          16.215140             13.406304   \n",
       "\n",
       "   p2_leg_attempted_ema  p1_distance_landed_ema  p2_distance_landed_ema  \\\n",
       "0              8.469213               64.249344               40.422319   \n",
       "1              3.333333               30.714286               44.333333   \n",
       "2              4.776462               48.708700               35.804908   \n",
       "3             10.133333               11.333333               30.400000   \n",
       "4             17.148962               61.410415              100.666911   \n",
       "\n",
       "   p1_distance_attempted_ema  p2_distance_attempted_ema  p1_clinch_landed_ema  \\\n",
       "0                 153.012147                  87.092312              0.629677   \n",
       "1                  61.571429                 119.666667              5.142857   \n",
       "2                  84.446725                  78.584300             28.599218   \n",
       "3                  20.333333                  47.933333              1.000000   \n",
       "4                 146.797878                 212.363614              0.302455   \n",
       "\n",
       "   p2_clinch_landed_ema  p1_clinch_attempted_ema  p2_clinch_attempted_ema  \\\n",
       "0              2.975746                 1.600867                 4.961387   \n",
       "1              3.333333                 5.714286                 4.666667   \n",
       "2              6.882920                34.564027                 9.668172   \n",
       "3              0.066667                 1.333333                 0.200000   \n",
       "4              3.201954                 0.677917                 3.210745   \n",
       "\n",
       "   p1_ground_landed_ema  p2_ground_landed_ema  p1_ground_attempted_ema  \\\n",
       "0              8.583959              1.518469                13.739364   \n",
       "1             11.428571              0.333333                16.857143   \n",
       "2              0.679374             15.244415                 0.915934   \n",
       "3              8.333333              1.466667                14.333333   \n",
       "4              2.112320              0.161172                 5.208649   \n",
       "\n",
       "   p2_ground_attempted_ema  p1_r1_head_landed_ema  p2_r1_head_landed_ema  \\\n",
       "0                 2.243207               7.499725               1.992489   \n",
       "1                 2.000000               5.285714              12.666667   \n",
       "2                17.090709               8.709677              13.189843   \n",
       "3                 2.266667              12.000000               4.933333   \n",
       "4                 0.349695              10.050556              11.164835   \n",
       "\n",
       "   p1_r1_head_attempted_ema  p2_r1_head_attempted_ema  p1_r1_body_landed_ema  \\\n",
       "0                 25.974974                  4.131527               3.184765   \n",
       "1                 20.571429                 45.333333               8.285714   \n",
       "2                 21.014663                 21.444879              11.351906   \n",
       "3                 24.666667                 12.400000               2.333333   \n",
       "4                 34.478522                 38.309402               4.698507   \n",
       "\n",
       "   p2_r1_body_landed_ema  p1_r1_body_attempted_ema  p2_r1_body_attempted_ema  \\\n",
       "0               1.563864                  5.100348                  1.722838   \n",
       "1               8.333333                 10.285714                 10.000000   \n",
       "2               3.692956                 12.464321                  6.984129   \n",
       "3               1.666667                  3.333333                  2.800000   \n",
       "4              10.136752                  6.146630                 14.217582   \n",
       "\n",
       "   p1_r1_leg_landed_ema  p2_r1_leg_landed_ema  p1_r1_leg_attempted_ema  \\\n",
       "0              6.583898              1.804759                 7.770555   \n",
       "1              9.000000              0.000000                10.285714   \n",
       "2              8.664712              1.015749                 9.436950   \n",
       "3              3.000000              4.266667                 3.666667   \n",
       "4              3.883096              6.283272                 4.330378   \n",
       "\n",
       "   p2_r1_leg_attempted_ema  p1_r1_distance_landed_ema  \\\n",
       "0                 1.867382                  14.666789   \n",
       "1                 0.000000                  20.857143   \n",
       "2                 1.392260                  17.914956   \n",
       "3                 4.800000                   8.666667   \n",
       "4                 6.597802                  18.613174   \n",
       "\n",
       "   p2_r1_distance_landed_ema  p1_r1_distance_attempted_ema  \\\n",
       "0                   4.508493                     33.379235   \n",
       "1                  21.000000                     38.857143   \n",
       "2                   8.209010                     29.654936   \n",
       "3                   9.600000                     17.000000   \n",
       "4                  27.526252                     44.685991   \n",
       "\n",
       "   p2_r1_distance_attempted_ema  p1_r1_clinch_landed_ema  \\\n",
       "0                      6.492636                 0.094732   \n",
       "1                     54.000000                 1.714286   \n",
       "2                     18.979856                10.704790   \n",
       "3                     18.600000                 0.666667   \n",
       "4                     59.010256                 0.017265   \n",
       "\n",
       "   p2_r1_clinch_landed_ema  p1_r1_clinch_attempted_ema  \\\n",
       "0                 0.313642                    0.438809   \n",
       "1                 0.000000                    1.714286   \n",
       "2                 2.588939                   13.144673   \n",
       "3                 0.066667                    0.666667   \n",
       "4                 0.007814                    0.267689   \n",
       "\n",
       "   p2_r1_clinch_attempted_ema  p1_r1_ground_landed_ema  \\\n",
       "0                    0.438894                 2.506867   \n",
       "1                    0.666667                 0.000000   \n",
       "2                    3.738738                 0.106549   \n",
       "3                    0.200000                 8.000000   \n",
       "4                    0.015873                 0.001720   \n",
       "\n",
       "   p2_r1_ground_landed_ema  p1_r1_ground_attempted_ema  \\\n",
       "0                 0.538977                    5.027834   \n",
       "1                 0.000000                    0.571429   \n",
       "2                 7.100598                    0.116325   \n",
       "3                 1.200000                   14.000000   \n",
       "4                 0.050794                    0.001850   \n",
       "\n",
       "   p2_r1_ground_attempted_ema  \n",
       "0                    0.790218  \n",
       "1                    0.666667  \n",
       "2                    7.102674  \n",
       "3                    1.200000  \n",
       "4                    0.098657  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import the first CSV file\n",
    "feature_df = pd.read_csv('ufc_features.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Drop the columns\n",
    "columns_to_drop = ['p1_fighter', 'p2_fighter', 'event_date'] #method\n",
    "feature_df = feature_df.drop(columns=columns_to_drop)\n",
    "cols_to_drop = [col for col in feature_df.columns if col.startswith('method_')]\n",
    "feature_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "# Clean all column names\n",
    "def clean_column_name(col):\n",
    "  return col.lower().replace(' ', '_').replace('.', '').replace('-', '_')\n",
    "\n",
    "# Apply to all columns\n",
    "feature_df.columns = [clean_column_name(col) for col in feature_df.columns]\n",
    "\n",
    "# # encode the referee using frequency\n",
    "# ref_counts = feature_df['referee'].value_counts()\n",
    "# feature_df['referee_freq'] = feature_df['referee'].map(ref_counts)\n",
    "# feature_df.drop(columns=['referee'], inplace=True)\n",
    "\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86c2b57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8176, 2, 72)\n",
      "Sample X[0]:\n",
      " [[ 3.50000000e+01  1.88649658e-01 -9.03898155e-01  9.27657219e-02\n",
      "   1.18725739e+00 -5.41339616e-02  1.04903771e-01  1.95423076e-01\n",
      "  -3.08185356e-01 -3.49743081e-01  1.16229940e-01 -4.40363611e-01\n",
      "   5.41652436e-01  7.57168057e-01 -4.13781079e-01 -1.43817431e-01\n",
      "  -2.73728966e-01 -3.82257504e-01 -4.82628892e-01 -1.55251502e-01\n",
      "  -4.66728100e-01 -5.82072121e-01  6.83563961e-02 -1.81819535e-01\n",
      "  -1.77201438e-01 -3.03542762e-01  1.77830293e+00 -4.51245059e-01\n",
      "   1.13359812e-01  8.41983267e-01 -4.22262436e-01 -3.01653048e-01\n",
      "   2.28696957e-01  6.83563961e-02  1.13359812e-01  1.47242305e+00\n",
      "   1.57678689e+00  1.69095464e+00  1.91396128e+00  9.10121235e-01\n",
      "   9.01540302e-01  4.43910978e-01  4.94186940e-01  4.25061863e-01\n",
      "   6.78194083e-01  3.23699837e-01 -2.02358640e-02  1.03749296e+00\n",
      "   1.36353082e+00  9.75063113e-01  1.27441339e+00  2.19638150e+00\n",
      "   2.03950032e+00  1.68887112e+00  1.64845411e+00 -7.40970557e-01\n",
      "  -6.83521842e-01  5.30778344e-01  6.58827787e-01 -8.63603447e-02\n",
      "   2.38142391e-01  1.43877662e-01  2.91666780e-01  1.55310406e+00\n",
      "   1.42305680e+00  7.17847351e-01  5.54820538e-01 -7.30447790e-01\n",
      "  -6.86674595e-01  1.15436246e-01  3.66432136e-01  4.00000000e+00]\n",
      " [ 3.50000000e+01 -1.13920070e+00 -8.67575665e-01  1.72614957e-01\n",
      "  -2.87885444e-01  9.98485713e-01  3.37437269e-02 -2.90171334e-01\n",
      "   1.27243658e-01 -9.00285490e-02  1.27338179e-01  1.03253195e+00\n",
      "   1.33659478e+00 -6.53929418e-01 -1.96090943e-02 -4.21164607e-01\n",
      "  -9.54999185e-01 -1.30449950e-01 -4.05153937e-01 -3.67834519e-01\n",
      "   6.38075848e-01  3.03573193e-01  6.03411693e-01 -1.48342027e-01\n",
      "  -2.31474108e-02 -3.86443745e-01  5.12966494e-01 -4.38570988e-01\n",
      "   2.13347483e+00  4.76684536e-01 -3.27663237e-01 -2.80469034e-01\n",
      "   1.00788257e+00  6.03411693e-01  2.13347483e+00  5.99851804e-01\n",
      "   5.14700303e-01  1.72568872e-01  2.73448052e-01  8.61624994e-01\n",
      "   2.36354409e+00 -6.56039563e-01 -8.78949614e-01 -6.40482315e-01\n",
      "  -9.02737024e-01  1.30237039e+00  1.23192271e+00  1.22727874e-01\n",
      "   2.34351972e-01  1.65785897e+00  1.72400549e+00  4.19451634e-01\n",
      "   3.89147595e-01  8.87042071e-01  6.58693913e-01 -2.18257522e-01\n",
      "  -1.37516665e-01 -4.37481559e-01 -4.34533933e-01 -7.80056747e-01\n",
      "  -9.43242649e-01 -3.29252198e-01 -4.90567240e-01 -1.36810161e-01\n",
      "  -2.58771771e-01 -4.39164714e-01 -7.47697245e-01 -5.73632615e-01\n",
      "  -6.03490347e-01 -3.88345809e-01 -3.91632202e-01  1.00000000e+00]]\n",
      "y shape: (8176,)\n",
      "Sample y: 1\n",
      "Features per fighter (excluding referee): ['height', 'weight', 'reach', 'slpm', 'str_acc', 'sapm', 'str_def', 'td_avg', 'td_acc', 'td_def', 'sub_avg', 'age_at_event', 'age_adjusted_slpm', 'age_adjusted_str_acc', 'age_adjusted_sapm', 'age_adjusted_str_def', 'age_adjusted_td_avg', 'age_adjusted_td_acc', 'age_adjusted_td_def', 'age_adjusted_sub_avg', 'kd_ema', 'sig_str_pct_ema', 'td_pct_ema', 'sub_att_ema', 'rev_ema', 'ctrl_ema', 'r1_kd_ema', 'r1_sig_str_pct_ema', 'r1_td_pct_ema', 'r1_sub_att_ema', 'r1_rev_ema', 'r1_ctrl_ema', 'sig_str_pct_detailed_ema', 'r1_sig_str_pct_detailed_ema', 'sig_str_landed_ema', 'sig_str_attempted_ema', 'total_str_landed_ema', 'total_str_attempted_ema', 'td_landed_ema', 'td_attempted_ema', 'r1_sig_str_landed_ema', 'r1_sig_str_attempted_ema', 'r1_total_str_landed_ema', 'r1_total_str_attempted_ema', 'r1_td_landed_ema', 'r1_td_attempted_ema', 'head_landed_ema', 'head_attempted_ema', 'body_landed_ema', 'body_attempted_ema', 'leg_landed_ema', 'leg_attempted_ema', 'distance_landed_ema', 'distance_attempted_ema', 'clinch_landed_ema', 'clinch_attempted_ema', 'ground_landed_ema', 'ground_attempted_ema', 'r1_head_landed_ema', 'r1_head_attempted_ema', 'r1_body_landed_ema', 'r1_body_attempted_ema', 'r1_leg_landed_ema', 'r1_leg_attempted_ema', 'r1_distance_landed_ema', 'r1_distance_attempted_ema', 'r1_clinch_landed_ema', 'r1_clinch_attempted_ema', 'r1_ground_landed_ema', 'r1_ground_attempted_ema', 'stance']\n",
      "Total features per fighter (including referee): 72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# --- Encode categorical features ---\n",
    "# Encode stances\n",
    "stance_le = LabelEncoder()\n",
    "all_stances = pd.concat([feature_df['p1_stance'], feature_df['p2_stance']])\n",
    "stance_le.fit(all_stances)\n",
    "feature_df['p1_stance'] = stance_le.transform(feature_df['p1_stance'])\n",
    "feature_df['p2_stance'] = stance_le.transform(feature_df['p2_stance'])\n",
    "\n",
    "# Encode referee (new additional categorical feature)\n",
    "referee_le = LabelEncoder()\n",
    "referee_le.fit(feature_df['referee'])\n",
    "feature_df['referee'] = referee_le.transform(feature_df['referee'])\n",
    "\n",
    "# --- Scale numeric features except categorical features ---\n",
    "numeric_feats = [\n",
    "    'height', 'weight', 'reach', 'slpm', 'str_acc', 'sapm', 'str_def',\n",
    "    'td_avg', 'td_acc', 'td_def', 'sub_avg', 'age_at_event',\n",
    "    # Adding fight history metrics\n",
    "    # 'days_since_last_fight', 'wins', 'losses', 'total', 'win_streak',\n",
    "    # Adding age-adjusted metrics\n",
    "    'age_adjusted_slpm', 'age_adjusted_str_acc', 'age_adjusted_sapm',\n",
    "    'age_adjusted_str_def', 'age_adjusted_td_avg', 'age_adjusted_td_acc',\n",
    "    'age_adjusted_td_def', 'age_adjusted_sub_avg',\n",
    "    # Adding EMA metrics\n",
    "    'kd_ema', 'sig_str_pct_ema', 'td_pct_ema', 'sub_att_ema', 'rev_ema',\n",
    "    'ctrl_ema', 'r1_kd_ema', 'r1_sig_str_pct_ema', 'r1_td_pct_ema',\n",
    "    'r1_sub_att_ema', 'r1_rev_ema', 'r1_ctrl_ema',\n",
    "    'sig_str_pct_detailed_ema', 'r1_sig_str_pct_detailed_ema',\n",
    "    'sig_str_landed_ema', 'sig_str_attempted_ema',\n",
    "    'total_str_landed_ema', 'total_str_attempted_ema',\n",
    "    'td_landed_ema', 'td_attempted_ema',\n",
    "    'r1_sig_str_landed_ema', 'r1_sig_str_attempted_ema',\n",
    "    'r1_total_str_landed_ema', 'r1_total_str_attempted_ema',\n",
    "    'r1_td_landed_ema', 'r1_td_attempted_ema',\n",
    "    'head_landed_ema', 'head_attempted_ema',\n",
    "    'body_landed_ema', 'body_attempted_ema',\n",
    "    'leg_landed_ema', 'leg_attempted_ema',\n",
    "    'distance_landed_ema', 'distance_attempted_ema',\n",
    "    'clinch_landed_ema', 'clinch_attempted_ema',\n",
    "    'ground_landed_ema', 'ground_attempted_ema',\n",
    "    'r1_head_landed_ema', 'r1_head_attempted_ema',\n",
    "    'r1_body_landed_ema', 'r1_body_attempted_ema',\n",
    "    'r1_leg_landed_ema', 'r1_leg_attempted_ema',\n",
    "    'r1_distance_landed_ema', 'r1_distance_attempted_ema',\n",
    "    'r1_clinch_landed_ema', 'r1_clinch_attempted_ema',\n",
    "    'r1_ground_landed_ema', 'r1_ground_attempted_ema'\n",
    "]\n",
    "\n",
    "p1_numeric = ['p1_' + f for f in numeric_feats]\n",
    "p2_numeric = ['p2_' + f for f in numeric_feats]\n",
    "\n",
    "# Handle potential NaN values\n",
    "feature_df[p1_numeric + p2_numeric] = feature_df[p1_numeric + p2_numeric].fillna(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "feature_df[p1_numeric + p2_numeric] = scaler.fit_transform(feature_df[p1_numeric + p2_numeric])\n",
    "\n",
    "# --- Prepare features per fighter (including stance) ---\n",
    "features_per_fighter = numeric_feats + ['stance']\n",
    "p1_features = ['p1_' + f for f in features_per_fighter]\n",
    "p2_features = ['p2_' + f for f in features_per_fighter]\n",
    "\n",
    "# --- Structure data for BiLSTM including referee as a global feature ---\n",
    "# Create a sequence of [referee, p1_features] and [referee, p2_features] for each sample\n",
    "X = np.stack([\n",
    "    np.hstack([feature_df[['referee']].values, feature_df[p1_features].values]),\n",
    "    np.hstack([feature_df[['referee']].values, feature_df[p2_features].values])\n",
    "], axis=1)  # shape: (num_samples, 2, 1+num_features_per_fighter)\n",
    "\n",
    "y = feature_df['winner'].values\n",
    "\n",
    "# --- Check the shapes and a sample ---\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Sample X[0]:\\n\", X[0])\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Sample y:\", y[0])\n",
    "print(\"Features per fighter (excluding referee):\", features_per_fighter)\n",
    "print(\"Total features per fighter (including referee):\", len(features_per_fighter) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe46a7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
       "\n",
       " referee              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " stance (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       "\n",
       " referee_embedding    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,856</span>  referee[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
       "\n",
       " stance_embedding     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>  stance[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
       "\n",
       " lambda_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  referee_embeddin \n",
       "\n",
       " lambda_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  stance_embedding \n",
       "\n",
       " numeric              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
       "\n",
       " concatenate_6        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lambda_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       lambda_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
       "                                                     numeric[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
       "\n",
       " bidirectional_12     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">75,264</span>  concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                                                       \n",
       "\n",
       " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>  bidirectional_12 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
       "\n",
       " dropout_12           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
       "\n",
       " bidirectional_13     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span>  dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                                                       \n",
       "\n",
       " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  bidirectional_13 \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
       "\n",
       " dropout_13           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
       "\n",
       " dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>  dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " referee              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " stance (\u001b[38;5;33mInputLayer\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
       "\n",
       " referee_embedding    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)         \u001b[38;5;34m1,856\u001b[0m  referee[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
       "\n",
       " stance_embedding     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4\u001b[0m)            \u001b[38;5;34m24\u001b[0m  stance[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
       " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
       "\n",
       " lambda_12 (\u001b[38;5;33mLambda\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m8\u001b[0m)                \u001b[38;5;34m0\u001b[0m  referee_embeddin \n",
       "\n",
       " lambda_13 (\u001b[38;5;33mLambda\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m4\u001b[0m)                \u001b[38;5;34m0\u001b[0m  stance_embedding \n",
       "\n",
       " numeric              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m70\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
       "\n",
       " concatenate_6        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m82\u001b[0m)               \u001b[38;5;34m0\u001b[0m  lambda_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
       " (\u001b[38;5;33mConcatenate\u001b[0m)                                       lambda_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
       "                                                     numeric[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
       "\n",
       " bidirectional_12     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)         \u001b[38;5;34m75,264\u001b[0m  concatenate_6[\u001b[38;5;34m0\u001b[0m] \n",
       " (\u001b[38;5;33mBidirectional\u001b[0m)                                                       \n",
       "\n",
       " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)            \u001b[38;5;34m256\u001b[0m  bidirectional_12 \n",
       " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
       "\n",
       " dropout_12           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)              \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
       " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
       "\n",
       " bidirectional_13     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m41,216\u001b[0m  dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       " (\u001b[38;5;33mBidirectional\u001b[0m)                                                       \n",
       "\n",
       " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m128\u001b[0m  bidirectional_13 \n",
       " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
       "\n",
       " dropout_13           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
       " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
       "\n",
       " dense_6 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                  \u001b[38;5;34m65\u001b[0m  dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,809</span> (464.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,809\u001b[0m (464.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,809</span> (464.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,809\u001b[0m (464.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m200/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5200 - loss: 0.9861 - precision: 0.5714 - recall: 0.6188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.5204 - loss: 0.9849 - precision: 0.5717 - recall: 0.6200 - val_accuracy: 0.8368 - val_loss: 0.4437 - val_precision: 0.9013 - val_recall: 0.9180\n",
      "Epoch 2/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5558 - loss: 0.8475 - precision: 0.5863 - recall: 0.7250 - val_accuracy: 0.8215 - val_loss: 0.4649 - val_precision: 0.9126 - val_recall: 0.8852\n",
      "Epoch 3/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5991 - loss: 0.7680 - precision: 0.6231 - recall: 0.7428 - val_accuracy: 0.8331 - val_loss: 0.4475 - val_precision: 0.9092 - val_recall: 0.9036\n",
      "Epoch 4/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6021 - loss: 0.7469 - precision: 0.6228 - recall: 0.7772 - val_accuracy: 0.8087 - val_loss: 0.4737 - val_precision: 0.9173 - val_recall: 0.8640\n",
      "Epoch 5/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6253 - loss: 0.7090 - precision: 0.6394 - recall: 0.7851 - val_accuracy: 0.8276 - val_loss: 0.4433 - val_precision: 0.9126 - val_recall: 0.8927\n",
      "Epoch 6/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6207 - loss: 0.7120 - precision: 0.6292 - recall: 0.8059 - val_accuracy: 0.8172 - val_loss: 0.4529 - val_precision: 0.9163 - val_recall: 0.8756\n",
      "Epoch 7/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6379 - loss: 0.6914 - precision: 0.6513 - recall: 0.8062 - val_accuracy: 0.8258 - val_loss: 0.4366 - val_precision: 0.9189 - val_recall: 0.8831\n",
      "Epoch 8/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6567 - loss: 0.6722 - precision: 0.6533 - recall: 0.8232 - val_accuracy: 0.8136 - val_loss: 0.4523 - val_precision: 0.9239 - val_recall: 0.8626\n",
      "Epoch 9/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6648 - loss: 0.6598 - precision: 0.6632 - recall: 0.8232 - val_accuracy: 0.7818 - val_loss: 0.4561 - val_precision: 0.9145 - val_recall: 0.8339\n",
      "Epoch 10/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6637 - loss: 0.6571 - precision: 0.6672 - recall: 0.8371 - val_accuracy: 0.8166 - val_loss: 0.4375 - val_precision: 0.9235 - val_recall: 0.8667\n",
      "Epoch 11/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6738 - loss: 0.6382 - precision: 0.6771 - recall: 0.8323 - val_accuracy: 0.7800 - val_loss: 0.4644 - val_precision: 0.9239 - val_recall: 0.8216\n",
      "Epoch 12/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6919 - loss: 0.6294 - precision: 0.6928 - recall: 0.8276 - val_accuracy: 0.7592 - val_loss: 0.4809 - val_precision: 0.9199 - val_recall: 0.8004\n",
      "Epoch 13/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6895 - loss: 0.6404 - precision: 0.6860 - recall: 0.8318 - val_accuracy: 0.7977 - val_loss: 0.4469 - val_precision: 0.9224 - val_recall: 0.8448\n",
      "Epoch 14/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6868 - loss: 0.6310 - precision: 0.6870 - recall: 0.8166 - val_accuracy: 0.7628 - val_loss: 0.4745 - val_precision: 0.9236 - val_recall: 0.8011\n",
      "Epoch 15/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7160 - loss: 0.6147 - precision: 0.7135 - recall: 0.8393 - val_accuracy: 0.7830 - val_loss: 0.4655 - val_precision: 0.9184 - val_recall: 0.8312\n",
      "Epoch 16/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7134 - loss: 0.6052 - precision: 0.7071 - recall: 0.8560 - val_accuracy: 0.7744 - val_loss: 0.4628 - val_precision: 0.9221 - val_recall: 0.8168\n",
      "Epoch 17/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7028 - loss: 0.6061 - precision: 0.7020 - recall: 0.8289 - val_accuracy: 0.7940 - val_loss: 0.4535 - val_precision: 0.9239 - val_recall: 0.8387\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Concatenate, LSTM, Bidirectional, Dense, Lambda, Dropout, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# --- CLEAN THE DATA ---\n",
    "X_clean = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "y_clean = y\n",
    "\n",
    "# --- PREPARE INPUTS FOR THE MODEL ---\n",
    "num_samples = X_clean.shape[0]\n",
    "num_features_per_fighter = X_clean.shape[2]  # Should be 77\n",
    "num_referees = int(X_clean[:,:,0].max()) + 1  # Referee is now first feature\n",
    "num_stances = int(X_clean[:,:,-1].max()) + 1  # Stance is last feature\n",
    "num_numeric = num_features_per_fighter - 2    # Exclude referee (0) and stance (-1)\n",
    "\n",
    "# Extract components\n",
    "referee_input = X_clean[:,:,0].astype(int)[..., np.newaxis]  # Shape: (samples, 2, 1)\n",
    "stance_input = X_clean[:,:,-1].astype(int)[..., np.newaxis]  # Shape: (samples, 2, 1)\n",
    "numeric_input = X_clean[:,:,1:-1]  # Shape: (samples, 2, 75)\n",
    "\n",
    "# --- BUILD ENHANCED MODEL ---\n",
    "input_referee = Input(shape=(2, 1), name='referee')\n",
    "input_stance = Input(shape=(2, 1), name='stance')\n",
    "input_numeric = Input(shape=(2, num_numeric), name='numeric')\n",
    "\n",
    "# Embedding layers with regularization\n",
    "emb_referee = Embedding(num_referees, 8, name='referee_embedding')(input_referee)\n",
    "emb_stance = Embedding(num_stances, 4, name='stance_embedding')(input_stance)\n",
    "\n",
    "# Squeeze embedding dimensions\n",
    "emb_referee = Lambda(lambda x: tf.squeeze(x, axis=2))(emb_referee)\n",
    "emb_stance = Lambda(lambda x: tf.squeeze(x, axis=2))(emb_stance)\n",
    "\n",
    "# Concatenate all features\n",
    "concat = Concatenate(axis=-1)([emb_referee, emb_stance, input_numeric])\n",
    "\n",
    "# Enhanced BiLSTM architecture\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(concat)\n",
    "x = LayerNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Bidirectional(LSTM(32))(x)\n",
    "x = LayerNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[input_referee, input_stance, input_numeric], outputs=output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', \n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall')])\n",
    "model.summary()\n",
    "\n",
    "# --- TRAIN WITH IMPROVED CALLBACKS ---\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model_enhanced.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [referee_input, stance_input, numeric_input],\n",
    "    y_clean,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop, checkpoint],\n",
    "    class_weight={0: 1, 1: 1.2}  # Adjust if class imbalance exists\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
